{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4fd1a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_csv(r'C:\\Users\\KamranImtiyaz\\OneDrive - MinoriLabs\\Desktop\\Agent\\New Ecom - Industry Segmentation _ Oct2025(WIP).csv')\n",
    "\n",
    "# Assuming the column with websites is named 'Website'\n",
    "websites = df['Website'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876db70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32043"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "websites[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_perplexity import ChatPerplexity\n",
    "from creds import perplexity_api_key\n",
    "\n",
    "# Initialize with your API key (it will pick from env variable if set)\n",
    "chat_perplexity = ChatPerplexity(model=\"sonar-medium\", temperature=0.2, api_key=perplexity_api_key, max_tokens=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dbe9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_perplexity(url):\n",
    "    prompt = (\n",
    "    f\"Analyze the website at {url}. \"\n",
    "    \"Evaluate its structure, content, and functionality to determine its primary purpose. \"\n",
    "    \"Classify the website into one of the following categories: \"\n",
    "    \"1) 'e-commerce' — if it primarily enables online sales or transactions and includes features such as product listings, shopping carts, checkout or payment gateways, customer accounts, promotional offers, or order tracking. \"\n",
    "    \"2) 'mark-ops' — if it focuses on marketing, branding, lead generation, or corporate communications, typically featuring sections like 'About Us', 'Services', 'Case Studies', 'Blog', or 'Contact Us' but without direct purchase options. \"\n",
    "    \"3) 'other' — if it does not clearly fit into either category. \"\n",
    "    \"Respond with only one of the following labels: 'e-commerce', 'mark-ops', or 'other'.\"\n",
    "    )\n",
    "\n",
    "    response = chat_perplexity.invoke(\n",
    "        input=prompt,\n",
    "\n",
    "        )\n",
    "    return response.content.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb1fa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "from google import genai\n",
    "from google.genai.types import Tool, GenerateContentConfig, GoogleSearch\n",
    "import json\n",
    "google_search_tool = Tool(google_search=GoogleSearch())\n",
    "\n",
    "from goog import GOOGLE_API_KEY\n",
    "\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "def classify_with_gemini(url):\n",
    "    prompt = (\n",
    "        f\"Analyze the website at {url}. \"\n",
    "        \"Evaluate its structure, content, and functionality to determine its primary purpose. \"\n",
    "        \"Classify the website into one of the following categories: \"\n",
    "        \"1) 'e-commerce' — if it primarily enables online sales or transactions and includes features such as product listings, shopping carts, checkout or payment gateways, customer accounts, promotional offers, or order tracking. \"\n",
    "        \"2) 'mark-ops' — if it focuses on marketing, branding, lead generation, or corporate communications, typically featuring sections like 'About Us', 'Services', 'Case Studies', 'Blog', or 'Contact Us' but without direct purchase options. \"\n",
    "        \"3) 'other' — if it does not clearly fit into either category or its a nan\"\n",
    "        \"Respond with only one of the following labels: 'e-commerce', 'mark-ops', or 'other'.\"\n",
    "    )\n",
    "    thinking_budget = 5000  # @param {type:\"slider\", min:0, max:24576, step:1}\n",
    "\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-preview-09-2025\",\n",
    "        contents=prompt,\n",
    "        config=GenerateContentConfig(\n",
    "            tools=[google_search_tool],\n",
    "            thinking_config=types.ThinkingConfig(\n",
    "                thinking_budget=thinking_budget,\n",
    "                include_thoughts=True\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    print(response)\n",
    "\n",
    "    # Updated error handling\n",
    "    if response is None or getattr(response, \"text\", None) is None:\n",
    "        return \"\"\n",
    "    return response.text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4088192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing code ...\n",
    "df.loc[:5, \"Category_perplexity\"] = df.loc[:5, \"Website\"].apply(classify_with_perplexity) \n",
    "# ... existing code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34a1a7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Analyzing Website Focus**\n",
      "\n",
      "I'm currently focused on dissecting the website's structure and content to pinpoint its core function. I'm actively analyzing search results for transaction-related keywords, contrasting those with informational or promotional terms. This should allow me to categorize the website as 'e-commerce', 'mark-ops', or something else entirely.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Attempting Content Discovery**\n",
      "\n",
      "I'm hitting a roadblock. My initial probes for the website's inner workings are failing. No structural or content data is surfacing. I'll switch gears and try a more targeted approach, seeking out the company or website's own descriptions.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Examining Website Availability**\n",
      "\n",
      "I'm frustrated. The second set of search queries were also fruitless, which is peculiar. It points to a new, poorly indexed, or perhaps defunct website. Since I lack direct information from search results, I can't classify the site's structure, content, or functionality.  The prompt forces a classification, and with no data, 'other' seems the only reasonable label, as the site's purpose remains unclear. I'll attempt a wider search, hoping to uncover it through social media or third-party listings.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Analyzing Web Domain Content**\n",
      "\n",
      "I've hit a dead end, unfortunately. My recent searches on \"car life\" and \"enjoy life drive slow\" yielded only general concepts about car culture. There's nothing about http://www.injoycarlife.com, its structure, or any indication of e-commerce features. Without this essential data, I cannot classify the site, and the most accurate label is 'other'.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text='other'\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEPLezqkIcdJK2cXO02v-M1DeGQg0gEMMx71rgrVEkvAJnUaA4S2BsjBxA9b8RKO3SwvTV9NLgRKOkZ5tDQ9hTKitiX8PYkDtOv5rEGRs0-YUaWpZUVuyNgHKgb6boiYD-BIAC0BiVgRy8tKuRB2CdCJgaSOs1SYXX4k3825ELcb92jvKrbEGnwMd2LfokDdA==\">injoycarlife</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE8B0PBZYy-ntawDHmv6DlN1FtJo7R3j-Tt9HOiDY1rTaaPU1djxrw5PosGaKc1BBWseMeDbXdnv_4AhfjagTPtltydFZ2t9tLQxjznhdDqcXTZ-FsjRjaWcURdYO5lQ_aqYzcVHdqoe-9VgEnF5jw_0lfXyABYSPaigIq6-03g3lHvJ7eoxh5DAql4_GeEOcbv\">injoy car life</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      'http://www.injoycarlife.com content and features',\n",
      "      'injoycarlife.com website purpose',\n",
      "      'injoycarlife.com \"About Us\" \"Services\" \"Products\"',\n",
      "      'what is injoycarlife.com',\n",
      "      'injoycarlife',\n",
      "      <... 1 more items ...>,\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='YzIUaZD6E4bljuMP7ojz0Q0' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=102,\n",
      "  prompt_token_count=181,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=181\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=594,\n",
      "  tool_use_prompt_token_count=1257,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=1257\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=2134\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Determining Site Purpose**\n",
      "\n",
      "I'm focusing on \"vivalamama.org\" and need to classify it. To uncover its core function, I'm formulating search queries. Currently, I'm leaning toward terms like \"website structure\", \"content\", and \"functionality\" to guide my investigation. I'll also try a simpler query to start: \"what is vivalamama.org\".\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Investigating Domain Similarity**\n",
      "\n",
      "The search result for \"vivalamamma.at\" reveals typical corporate website functionality for \"Viva la Mamma Gastronomie GmbH.\" This includes content delivery, communication (contact forms, email), marketing (newsletters), and data collection, but not e-commerce features. However, the `.org` domain remains unverified. I am now focusing on a more targeted search to confirm the nature of \"vivalamama.org\" and its possible relation to \"vivalamamma.at.\"\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Classifying Website Purpose**\n",
      "\n",
      "I've analyzed the website and its functions.  The initial search results point consistently to a restaurant, Viva la Mamma. The website, as revealed by its structure and content like the menu, reservation options, and event inquiries, seems designed for marketing and service bookings. While there are vouchers, without an explicit e-commerce checkout flow for the main food items, it strongly leans towards a 'mark-ops' classification over 'e-commerce'. I'll proceed with this classification.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"The website's structure, which includes sections like \"MENU,\" \"LUNCH,\" \"WINES,\" \"DRINKS,\" \"RESERVATIONS,\" \"Event Anfrage,\" \"VOUCHERS,\" and contact information, indicates it is the online presence for a gastronomy (restaurant) business.\n",
      "\n",
      "The content focuses on:\n",
      "1.  **Information and Branding:** Displaying the menu with pricing and detailed descriptions.\n",
      "2.  **Lead Generation/Communication:** Offering a newsletter sign-up and rapid electronic contact via email or a contact form.\n",
      "3.  **Service Booking/Facilitation:** Providing options for \"RESERVATIONS\" and \"Event Anfrage.\"\n",
      "\n",
      "While it lists prices and has a \"VOUCHERS\" section, it lacks the explicit core features of an e-commerce site for its primary products (food and drinks), such as a shopping cart, a checkout process, or order tracking for menu items. Its function is to market the restaurant, provide necessary information, and facilitate in-person transactions and bookings. This aligns with the 'mark-ops' classification.\n",
      "\n",
      "mark-ops\"\"\"\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    grounding_chunks=[\n",
      "      GroundingChunk(\n",
      "        web=GroundingChunkWeb(\n",
      "          title='vivalamamma.at',\n",
      "          uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGfM2nY01wXBafkXvASy05F393YYaYmqIXf44zf6pnjGPWclj2OjuqaYjzUF5RKFVhr9KsVbSI96fyZkQSGzhEgQ5tQWgnHgwQNHapeJjQL0tUdImxU1Tpd-6zG0V1RctKFRQAsgnJU2EyW_FIiqw=='\n",
      "        )\n",
      "      ),\n",
      "      GroundingChunk(\n",
      "        web=GroundingChunkWeb(\n",
      "          title='vivalamamma.at',\n",
      "          uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE-_G9XuamdI2aMR4vFT9hPiahfNepMfm8HVjMKJoEp5GCmgs0iR4afbJd-4VF2y1CC03JE--GUjS9il2w5jaXn98aaN266v5jc736-XVVLyJ29TiDgoVnfwEJeMUuzU4QVMntF'\n",
      "        )\n",
      "      ),\n",
      "    ],\n",
      "    grounding_supports=[\n",
      "      GroundingSupport(\n",
      "        grounding_chunk_indices=[\n",
      "          0,\n",
      "          1,\n",
      "        ],\n",
      "        segment=Segment(\n",
      "          end_index=235,\n",
      "          text='The website\\'s structure, which includes sections like \"MENU,\" \"LUNCH,\" \"WINES,\" \"DRINKS,\" \"RESERVATIONS,\" \"Event Anfrage,\" \"VOUCHERS,\" and contact information, indicates it is the online presence for a gastronomy (restaurant) business.'\n",
      "        )\n",
      "      ),\n",
      "      GroundingSupport(\n",
      "        grounding_chunk_indices=[\n",
      "          0,\n",
      "        ],\n",
      "        segment=Segment(\n",
      "          end_index=354,\n",
      "          start_index=265,\n",
      "          text='**Information and Branding:** Displaying the menu with pricing and detailed descriptions.'\n",
      "        )\n",
      "      ),\n",
      "      GroundingSupport(\n",
      "        grounding_chunk_indices=[\n",
      "          1,\n",
      "        ],\n",
      "        segment=Segment(\n",
      "          end_index=481,\n",
      "          start_index=359,\n",
      "          text='**Lead Generation/Communication:** Offering a newsletter sign-up and rapid electronic contact via email or a contact form.'\n",
      "        )\n",
      "      ),\n",
      "      GroundingSupport(\n",
      "        grounding_chunk_indices=[\n",
      "          0,\n",
      "        ],\n",
      "        segment=Segment(\n",
      "          end_index=577,\n",
      "          start_index=486,\n",
      "          text='**Service Booking/Facilitation:** Providing options for \"RESERVATIONS\" and \"Event Anfrage.\"'\n",
      "        )\n",
      "      ),\n",
      "    ],\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG3xcSSt8rAVwAnUBIvtRbzB0e6t_bp7wYnsNrYvOcKwuEv4uQwhP2kCs9EjUcorhGE3LxSqoYa16Kr2yv2l2Zr39xpz9GGbmWoEJ2q--zCrmeqhpogK5g7kY7CbswnRz0SYKWgc5Bb0xsxcP_nmHqwjdu7XVxZ7_vQo0K1J_YrK5XsOhDCNzDFOc9mqZoftuIcWG_aGEU5gGDStKGj3w==\">vivalamama.org menu pricing</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF9GGPi6wUQpsHph-LMZU_tedzjAvPIRi8lxO9HriEzkfRV9iqH-_2-0k4WG-ljFhImpfp5l51SF4f152VouqqgrzgQV0A21hWIemv2av-zpMOioUe2kjdRLBF4ltM0ccp_de7quIV_q041-KOvas010HHwpCkg1YW_6Ln9EC1X-j95_0O25Z4Pxl5Pm-83mlpmGISvtt5kJ-EzCJOIqzVW6ZE=\">vivalamama.org website sections</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      'vivalamama.org website purpose content functionality',\n",
      "      'what is vivalamama.org about',\n",
      "      'vivalamama.org website sections',\n",
      "      'vivalamama.org menu pricing',\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='bTIUabmBIanHjuMPpOLfwAw' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=287,\n",
      "  prompt_token_count=179,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=179\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=917,\n",
      "  tool_use_prompt_token_count=827,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=827\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=2210\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Examining Web Presence**\n",
      "\n",
      "I'm now diving into the online presence of \"aalberts-ips.us.\" My initial plan is to analyze its structure, content, and functions using Google. I've formulated a few search queries, including variations focused on its primary purpose and, crucially, if it has any e-commerce capabilities like a shopping cart and checkout process.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Evaluating Website Features**\n",
      "\n",
      "I've examined the features of the site further, focusing on its e-commerce capabilities. While product listings and \"my IPS\" functionality exist, the absence of a clear shopping cart or checkout process, coupled with the emphasis on saving product lists and creating submittal packages, strongly suggests a focus on B2B lead generation rather than direct online sales. This is supported by the availability of design services, technical resources, and B2B solutions. I'm now certain mark-ops is the better fit.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"The website exhibits the following characteristics:\n",
      "\n",
      "**Structure and Content:**\n",
      "*   It features extensive information about the company (\"About Us,\" \"Our Story,\" \"Quality Commitment,\" \"Sustainability\").\n",
      "*   It includes sections for \"Services\" (e.g., Aalberts IPS design service, Revit plug-in, sizing tools, field services).\n",
      "*   It provides a comprehensive \"commercial products catalog\" and \"Resources\" (catalogs, data sheets, price lists, BIM content).\n",
      "*   It includes corporate communications elements like a \"newsroom\" and \"case studies\".\n",
      "\n",
      "**Functionality (E-commerce Evaluation):**\n",
      "*   The primary advanced functionality is **\"my IPS,\"** a digital workspace that allows users (likely B2B professionals like contractors and engineers) to **save product lists** and **compile/customize submittal packages**. These features are tools for product specification and lead generation in a B2B sales cycle.\n",
      "*   While it mentions \"my orders\" and \"saved products\", and \"price lists\", there is no explicit evidence of a **\"shopping cart,\" \"checkout,\" or \"payment gateway,\"** which are the core features of the 'e-commerce' category as defined. The presence of a \"return policy\" and \"freight policy\" is common for any company that ships products, regardless of whether the order is placed directly on the site.\n",
      "\n",
      "**Conclusion:**\n",
      "The website's structure and content are overwhelmingly focused on branding, corporate communication, and providing extensive technical and marketing resources to enable professionals to *specify* and *design* using their products. The primary purpose is B2B marketing, sales support, and lead generation, rather than direct online sales transactions.\n",
      "\n",
      "mark-ops\"\"\"\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    grounding_chunks=[\n",
      "      GroundingChunk(\n",
      "        web=GroundingChunkWeb(\n",
      "          title='aalberts-ips.us',\n",
      "          uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFKTQ_Mz7cV9eNzX7j7RtEkQQIEs79hqZM-9-4roLJpSo0nDXbILhpP8F1fWB08wLiWnDaFESc94IzdNjYaUMT17cuYR73Yhwu77PuNVkuRsaRsO79_9A4g96x4UJ9v9QfvMj6uUXnZeN9yHpuVPrVNrzQjbGB-mNY='\n",
      "        )\n",
      "      ),\n",
      "      GroundingChunk(\n",
      "        web=GroundingChunkWeb(\n",
      "          title='aalberts-ips.us',\n",
      "          uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFRUQabxKsPK5fcJi2-SLNhafv0B-2WrrQvFftmErW4K0Hmluw5XV10bGerzEe6jLCeL9amQup0kQA1fD8swCDh_oGSKYnNPk7zDcZt2R8vl-wATYXhg8mhP74YNGp_CyAjVA=='\n",
      "        )\n",
      "      ),\n",
      "      GroundingChunk(\n",
      "        web=GroundingChunkWeb(\n",
      "          title='aalberts-ips.us',\n",
      "          uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFJdIW51iakHgCKWdRQxvosUVMdt6x5XYVwrrFtlhBTO4wceR3KFB0q19FGPQKOR5hGyR8cD_cPN_EvXXxG9tgYfJAtXdzLrPXF7d4VD5gaDHN_8sFO0TaW88THVg5CwY7JLNojyhbSqmKy-uHfMRvCUKwwRr4='\n",
      "        )\n",
      "      ),\n",
      "      GroundingChunk(\n",
      "        web=GroundingChunkWeb(\n",
      "          title='aalberts-ips.us',\n",
      "          uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFGYEDDXRDKP9VNBhdbEYP72x8PLURn53q_BH9qZxMQA2GOFwgmhHqV3ztqzL2JT2Y76G8mpynhG888Y8TyNDOLTWp-Euw4giINPnrO4XjvZaHvq7iduJRHhMRFPQ=='\n",
      "        )\n",
      "      ),\n",
      "      GroundingChunk(\n",
      "        web=GroundingChunkWeb(\n",
      "          title='aalberts-ips.us',\n",
      "          uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHYKBoCG-MmGEALL5TwY0kQtmeqw2BzgoTboy4bpfVq7SX6SiFD6fv7u8LZyAfQqGuKRlEkosX0algscEk00x2QPZLDs5zh9_jxEBrVcZUgMV3vMQ=='\n",
      "        )\n",
      "      ),\n",
      "      <... 1 more items ...>,\n",
      "    ],\n",
      "    grounding_supports=[\n",
      "      GroundingSupport(\n",
      "        grounding_chunk_indices=[\n",
      "          0,\n",
      "          1,\n",
      "        ],\n",
      "        segment=Segment(\n",
      "          end_index=201,\n",
      "          start_index=53,\n",
      "          text=\"\"\"**Structure and Content:**\n",
      "*   It features extensive information about the company (\"About Us,\" \"Our Story,\" \"Quality Commitment,\" \"Sustainability\")\"\"\"\n",
      "        )\n",
      "      ),\n",
      "      GroundingSupport(\n",
      "        grounding_chunk_indices=[\n",
      "          0,\n",
      "          2,\n",
      "        ],\n",
      "        segment=Segment(\n",
      "          end_index=323,\n",
      "          start_index=203,\n",
      "          text='*   It includes sections for \"Services\" (e.g., Aalberts IPS design service, Revit plug-in, sizing tools, field services)'\n",
      "        )\n",
      "      ),\n",
      "      GroundingSupport(\n",
      "        grounding_chunk_indices=[\n",
      "          0,\n",
      "          3,\n",
      "          2,\n",
      "        ],\n",
      "        segment=Segment(\n",
      "          end_index=452,\n",
      "          start_index=325,\n",
      "          text='*   It provides a comprehensive \"commercial products catalog\" and \"Resources\" (catalogs, data sheets, price lists, BIM content)'\n",
      "        )\n",
      "      ),\n",
      "      GroundingSupport(\n",
      "        grounding_chunk_indices=[\n",
      "          0,\n",
      "        ],\n",
      "        segment=Segment(\n",
      "          end_index=540,\n",
      "          start_index=454,\n",
      "          text='*   It includes corporate communications elements like a \"newsroom\" and \"case studies\"'\n",
      "        )\n",
      "      ),\n",
      "      GroundingSupport(\n",
      "        grounding_chunk_indices=[\n",
      "          4,\n",
      "          1,\n",
      "        ],\n",
      "        segment=Segment(\n",
      "          end_index=808,\n",
      "          start_index=543,\n",
      "          text=\"\"\"**Functionality (E-commerce Evaluation):**\n",
      "*   The primary advanced functionality is **\"my IPS,\"** a digital workspace that allows users (likely B2B professionals like contractors and engineers) to **save product lists** and **compile/customize submittal packages**\"\"\"\n",
      "        )\n",
      "      ),\n",
      "      <... 3 more items ...>,\n",
      "    ],\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFQaFsMtwD6Vu5VrdJUGWxNGVvpnlDZX8ot130oBT7ihkuVQhvUf_yRfMKyoT29cJR1XmzHHdQTqd7TwZeNibeSsGeVQ1Op0cpa_24gvo8vw_2-XwNo66ab2p0pzrLgG497lKY_YhEUB_dsnBhsliDvK_CggOkFD3yxkGoTLH4rzCN3Hkj7xr74Kt9UGqEk7cVTHsqgW-c5Txy62hh5vYlsBwvmJLYSM0O-HbPEwjvIij4xd2_Pwn4Tt2fM\">aalberts-ips.us product listings shopping cart checkout</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEm0icG35UuEFSxIgxecAhjtZuG8AWGlnQLw_HlV106SJzeWxYm_5QLdtrINiC7BbYVCj5sjQCo25Du9n8ZYhGnW_faTFwV6t2G_gAtI8ILw4MS8FvOFxKfYxSSKYASbS9FQtO5__G3oS0FQA4CwZqieEeG1eDZQ-82o7g5fh5cWayfD4kGtSFyWwGlqmiNe3NLGkH2GjmMJitpdVAj7EWXK4cMioMJRzfE4t9FIuOR-mKCVt3HxvJeukS527wm8A==\">aalberts-ips.us website primary purpose e-commerce mark-ops</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      'aalberts-ips.us website primary purpose e-commerce mark-ops',\n",
      "      'aalberts-ips.us product listings shopping cart checkout',\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='eDIUaeqVBqeVg8UPpfffuAw' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=395,\n",
      "  prompt_token_count=180,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=180\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=1057,\n",
      "  tool_use_prompt_token_count=287,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=287\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=1919\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Defining Website Category**\n",
      "\n",
      "I am currently focused on gathering information about the website. I started by formulating a search query to analyze the website structure, content, and functionality. My query specifically targets keywords related to 'online sales,' 'transactions,' 'product listings,' 'shopping carts,' 'checkout,' 'payment gateways,' 'About Us,' 'Services,' 'Case Studies,' 'Blog,' 'Contact Us,' 'marketing,' 'branding,' 'lead generation,' or 'corporate communications.' My next step is to classify the website as 'e-commerce', 'mark-ops', or 'other'.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Classifying Program Focus**\n",
      "\n",
      "I've determined that the \"cacollegecorps.com\" website aligns strongly with mark-ops or corporate communication goals. It's clear that the site's primary function is to inform and recruit students for the program. The content, including \"About Us,\" \"Contact Us,\" and program details, supports this classification. 'E-commerce' is definitely out.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text='mark-ops'\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHV8wZCA4kQFhBO2ASszISbu6Cg67ZXyNOV5gy3LOOe-yQVKei78cKC2KCC8Zys_HgQFglSlUWdrdMnn7XESToh-rKx-Fm4A7NyzG8DZ1xbU2XZ7apKpv_m7T8BgRl3hI_vmIKBGJsv9iUjJivseyLdy_6sAVFKcLZ8fNiojM6rsaXOkmLV0bNdImPE1n35o7vncepzmtN9i4M6YuxwiHbMJ4V98eAmmPbgtGcM\">cacollegecorps.com shopping cart checkout</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHbBFwFe70VN9OYXiLQKoAjq2hVRZ61aQbRo2JIWhYdI04s0XZnM1EvlyH98y_djaPYPdFJCIjv6-WsVv-74Pu1xmPDXy-SWyQn8kekomcuchTthHY8qHG3DcEeZWKieNecQSME-tMrWz07qTr_UBPYxXkTgId_G54-XAZ35lfs9a-BG3OQ-fQESFiyCTAXjU0UcEuZ4RSH5MPbM45zn_ZVFqAfYnOWZHzri3CGSHpxNBrb5P6dgRt8JqY2eXIDh8otjkqGVTw=\">cacollegecorps.com website structure content functionality purpose</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF019eQvBeePWcXoVFrwn97tVdC1RAb0m8pXArsCSLobjhadALfen-SpyBd1uZXIcETJhQiKmiuSkFK-jGPEnngb3-wkGwVc0gHCUq4QDYze6wBMbPH4lqjFx--ct2uVnnueEZtM41jCSd0CK75jG43f36dyIERUq_FD-ehmJ0YuijQSbJbE3JweGBzwHRvdOeh2iTgywhWmmflNCw9gAupMyaIQ-bJDX9hF-CK\">cacollegecorps.com about us services blog</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      'cacollegecorps.com website structure content functionality purpose',\n",
      "      'cacollegecorps.com shopping cart checkout',\n",
      "      'cacollegecorps.com about us services blog',\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='fjIUacHZJMy1juMPzq7AiQg' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=52,\n",
      "  prompt_token_count=181,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=181\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=469,\n",
      "  tool_use_prompt_token_count=309,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=309\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=1011\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Commencing website analysis**\n",
      "\n",
      "I'm currently focused on the website's content, structure, and functionality, using these features to discern its core purpose. The intent is to evaluate the collected information against predefined criteria, leading to a definitive classification of the site.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Evaluating Primary Purpose**\n",
      "\n",
      "I've been examining the ISSA website, and it's looking increasingly clear that its core function is e-commerce. While it has marketing and operational components, the presence of direct sales mechanisms like \"Buy Now\" and \"ADD TO CART\" decisively points to online sales of educational courses as the primary focus. The payment plans and clear pricing structure strengthen this classification.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text='e-commerce'\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFltq236n3KNI7NDckYx30-Nr48GHU3W4_r--hckH521ahQ9KBluK5lWFahZ1c0x2EX0pdInFKLMyV23Ey9VudXFYnbGSJpuCH3S2cjSajlampAU8d2YouZaNUb1NGfCT23pYNVGaYqf05auMsJpcutDJ8cbs4pJADs85I4qCteYTMhx5Aq2loH7vhE9yavIcVoNfcVrcXcgzJEB4tHT3BlZE_q_BRa2A==\">issaonline.com structure and content</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF9RBJDE6JuHIKoFCuqvQ_jlFhn7NR5C52LN4oiAB7GKAKvLX5anBO97Ne8IgtVu3O34KCWz1t1-cT0unJ3CAXkYvJz2wyRG6mS9BbHdHatALNBP0CqbqgCTvV4I4Z7PllKDNkOhXkX4bAT5IsyiCvqt0_ObDmD0mNnOSxhzQnwusl_pPgutr7OodRJdYqse6PkeRG3vimp2vIFicoUGzNF-Wd4rnmkJCEf0M8IquGHxDP5mqYJMYFs\">issaonline.com website purpose content functionality</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      'issaonline.com website purpose content functionality',\n",
      "      'issaonline.com structure and content',\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='hTIUaZyNF43Lg8UP7N-Z8Q4' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=32,\n",
      "  prompt_token_count=178,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=178\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=643,\n",
      "  tool_use_prompt_token_count=254,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=254\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=1107\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Examining Website Classification**\n",
      "\n",
      "I'm currently focused on the initial search for \"http://www.red.org\" to dissect its components. My next step will be to search for telltale signs of e-commerce features within the search results. Simultaneously, I'll be sifting through the content to identify indicators suggesting a marketing and operations focus. My goal is to synthesize the collected information for a final classification: e-commerce, mark-ops, or other.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Revising Classification Approach**\n",
      "\n",
      "I've determined that www.red.org isn't e-commerce because it pushes users to other sites for product purchases. It also leans toward marketing operations due to its emphasis on branding, advocacy, and lead generation. This seems to be the best description for it. However, because it also solicits donations, it is also a non-profit/fundraising type of site.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text='mark-ops'\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEVM8x1VON6v4UI9USxNU0eU2tDlrkPRR4OyFBlWdNIA5DpT8Th1o_iXMzmvbJBjZEvM_iiTBAnSmK-EBdK-ZLbw6K2ozGhd5MRYXDOsxU8lXJG3TENn_Z7-KhbVojwz6TfMmRaCoN9hGVauH35KUYUjDxjV5KRs7mM9FEiHheDQyVuQauZrEMJyfhDrCCf6dWcdsNBSBRbVrChUv9QR0lshkpDSIyXDjRv16UtnjVyYDkL\">http://www.red.org website content and features</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHdPqwvWxE7WUb2Y-nEPVpYjRg14RJHhsF2ya12V0_xPVN-eLvPPV7VJU_VJ99TY9TGsv4E2HabVUTTZdgm0o0gTAvr0TMuOlSjKL2puTMJjvVN_HII7pDleK_tbWzeuFopNtpwtaFgqMpQDiRcnXy92yvtxdiSpZTJqZtMCmvPyffaY6ZC-w1Sx8dR9Mkp2yRs_hob7iUEaxQBZ0tgnygO_aNLu3s=\">http://www.red.org website purpose</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      'http://www.red.org website purpose',\n",
      "      'http://www.red.org website content and features',\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='hTIUaeCNNOzFjuMPpOv82A4' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=37,\n",
      "  prompt_token_count=177,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=177\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=1259,\n",
      "  tool_use_prompt_token_count=333,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=333\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=1806\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Investigating WellboreIntegrity**\n",
      "\n",
      "I'm now focusing on the website \"http://www.wellboreintegrity.com.\" I've begun to crawl the website, and I'm looking into the structure. My current focus is to identify key sections and content types, paying attention to the presence of e-commerce indicators. I plan to use these to classify the website.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Pinpointing Marketing Purpose**\n",
      "\n",
      "I've been analyzing the search results for Wellbore Integrity Solutions.  I've identified key services, products, and corporate elements like \"About Us\" and \"Contact.\" My current focus is solidly on their function as a B2B marketing hub, emphasizing lead generation for complex services and industrial products, not direct online sales.  I'm convinced this is the correct classification.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text='mark-ops'\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGxbB60Kdn5ASk3R5FWVlnaZZXv7xJ87t_GLLeIHnG_mLaHIgnexIejjmXvr29quY79PvvWTE8p4ltgsQ89iWr-Jh21Cp6Ve6FYIdnBl3FrhGJyiA5aC2KjZ9dPM6GC4yxm1I0k5K2yT1kVrIaom8IYMVoGbfIjsmitCW2-2pGhxtY9GGxQF7-JTP_g4-ueFk9UuGTXUDaLOQCWR7L674g5SGvdM_S5NQoBVw==\">wellboreintegrity.com services products</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQH3B5pOxQo9OBUAfXSHQOJiFz41aQUsn1InpDx_OjWcwCV49g9jLSs7-UaUZcdk-9hWJ7LTxGKFkOsW2tPdg12fMAqUkJnW4C_3LhX7LehwY4jr9FUYkBW9d-grKaCX3xv8Vbwvb_zIt3Ybz1VUogU5ZmlK_srXjVdvuyHtD3ihrV5fwxgWxxG3nzRQTMfsCodkeyNw8BUka_aFgvdDBoYUSOZDhVuSd-HF\">wellboreintegrity.com website analysis</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      'wellboreintegrity.com website analysis',\n",
      "      'wellboreintegrity.com services products',\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='kDIUaafxCOK4juMP2v7wmQs' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=31,\n",
      "  prompt_token_count=179,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=179\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=518,\n",
      "  tool_use_prompt_token_count=321,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=321\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=1049\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Determining Website Function**\n",
      "\n",
      "I'm currently focused on the website http://www.asconoil.com. My initial assessment involves analyzing the site's structure, content, and interactive elements. I'm actively looking for telltale signs of e-commerce functionality, like product listings and shopping carts. Simultaneously, I'm examining sections indicative of marketing operations, such as \"About Us\" and \"Contact Us\" pages. Ultimately, I will classify the site as either 'e-commerce', 'mark-ops', or 'other'.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Expanding Search Parameters**\n",
      "\n",
      "I've realized the initial Google search wasn't going to give me a direct structural analysis. Typical search results are meant to point me to existing information, not conduct an on-the-fly website examination. Given the domain \"asconoil.com,\" I'm now trying a more focused search with terms like \"Ascon Oil\" and \"website\" to find existing descriptions or an 'About Us' section that could shed light on the website's core function.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Determining Website Purpose**\n",
      "\n",
      "I've gathered substantial information on the \"Ascon Group\" and \"Ascon Oil Company Ltd.\"  The focus is clearly on international B2B oil and commodities trading. I've identified key website sections like \"About Us,\" \"Business,\" \"Compliance,\" and \"Contact.\" The lack of e-commerce features confirms the website's primary function is to showcase the company's profile, services, and corporate responsibility to potential partners. This aligns perfectly with a \"mark-ops\" definition, so I've reached a firm conclusion. No further research is needed.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text='mark-ops'\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGlfXxR89lXuD2kFQDehm4UyTfKjan-Ll947hCzTOsDR6YQ9ZJPCzx6NndHEadCgiFFeNF0T6Qm3tB58ZrlrpNSfcnIIwRYu-LuYqleeajgP32RpEvIOt1P5vtaHGPvt8qO7o_VgwG6M0dcHqe998f-dfdvz7hTMeOhKRx2wATyc8Uf5qRdPUIwvSSOvKUtOcjIbfap_jxpvdoAzNiF\">Ascon Oil website sections</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFBsVCcMJ6Lf3vhjhnn97H8l9YvbRbstG1Fi9U19ZJZudjTwLRuvhI7YU3cRKN--6Od51l27Kn2EvRsIKwS8etVTrb6oB80nOWAraqrWWsfOr56T4V551eRYT6gXPBOPONLZr2YB_RZL5tXed8j9esaegApSs_xN8lnUwURp7vZ32isoz4US1MTmrdfe_Zv8lKeU0HUutFhAVTT0pFgw6dujJgo4Q==\">Ascon Oil website content purpose</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      'analyze website http://www.asconoil.com structure content functionality',\n",
      "      'Ascon Oil website content purpose',\n",
      "      'Ascon Oil website sections',\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='njIUaY34MZb-g8UPw6PC0AY' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=55,\n",
      "  prompt_token_count=179,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=179\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=694,\n",
      "  tool_use_prompt_token_count=796,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=796\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=1724\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Assessing Site Purpose**\n",
      "\n",
      "I'm currently working to determine the primary purpose of \"http://www.commarketing.com\". I'm relying on the `google_search` tool to gather information about its structure and content since I can't browse directly.  I'm focusing on keywords like \"services,\" \"case studies,\" and \"contact us\" to see if it leans toward marketing and lead generation or e-commerce functionalities like \"shopping cart\" and \"checkout.\" The aim is to classify it as either 'mark-ops' or 'e-commerce'.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Refining Categorization Focus**\n",
      "\n",
      "I've been working through the categorization of \"commarketing.com\" and I've honed in on its nature. It's become clear that while the platform offers commerce tools, the website itself is predominantly geared towards lead generation, branding, and explaining its B2B SaaS offerings.  I see a distinct focus on showcasing services, solutions, and encouraging contact for sales, confirming the `mark-ops` categorization.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"The website at http://www.commarketing.com (which appears to be CM.com based on the search analysis) is a B2B platform that offers various products and solutions for customer engagement, marketing, commerce, and service.\n",
      "\n",
      "Its structure and content are characterized by:\n",
      "*   Sections detailing **Products** (like Marketing Cloud, AI agents, Customer Data Platform, Conversational AI Cloud) and **Solutions/Industries** (like Financial Services, Retail & eCommerce).\n",
      "*   Focus on corporate communications, branding, and lead generation, with features typical of a B2B corporate site, such as detailing their services/platform and encouraging contact or a demo.\n",
      "\n",
      "While the platform *they sell* includes **Commerce** features like \"Online Payments\" and \"Ticketing\" for *their customers*, the website itself is structured to market and explain their business solutions, generate leads, and facilitate a sales process rather than enable a direct, immediate, retail-style online purchase (with a shopping cart and checkout) of their B2B platform.\n",
      "\n",
      "Therefore, its primary purpose is marketing, lead generation, and corporate communication for its platform and services.\n",
      "\n",
      "mark-ops\"\"\"\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    grounding_chunks=[\n",
      "      GroundingChunk(\n",
      "        web=GroundingChunkWeb(\n",
      "          title='cm.com',\n",
      "          uri='https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHm2p0oaKVvvApJlYmDUg-xjvMg6hS9Vpp5kbljZJlJ7kHQY2_ClYLzvFRCpwfshMqHil9HHE6_tilzM1BTCzkd1axdELycQPbH37RZjA=='\n",
      "        )\n",
      "      ),\n",
      "    ],\n",
      "    grounding_supports=[\n",
      "      GroundingSupport(\n",
      "        grounding_chunk_indices=[\n",
      "          0,\n",
      "        ],\n",
      "        segment=Segment(\n",
      "          end_index=464,\n",
      "          start_index=222,\n",
      "          text=\"\"\"Its structure and content are characterized by:\n",
      "*   Sections detailing **Products** (like Marketing Cloud, AI agents, Customer Data Platform, Conversational AI Cloud) and **Solutions/Industries** (like Financial Services, Retail & eCommerce).\"\"\"\n",
      "        )\n",
      "      ),\n",
      "      GroundingSupport(\n",
      "        grounding_chunk_indices=[\n",
      "          0,\n",
      "        ],\n",
      "        segment=Segment(\n",
      "          end_index=658,\n",
      "          start_index=465,\n",
      "          text='*   Focus on corporate communications, branding, and lead generation, with features typical of a B2B corporate site, such as detailing their services/platform and encouraging contact or a demo.'\n",
      "        )\n",
      "      ),\n",
      "    ],\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGxPcPJHYIU37EU5bniiVr4FWPKQfSDQ4Wg7mdmtOLCFC45rijCicFEiiXOrYo-yKmEerJ0m2mhNsqbYPC_MaCkawqYR62a-uhuwn8oYmY2c3kjCkybX603yV1S5fG9L8XFw2l6Ua_fkXyYnxKjypljEomrLXB-KWeH7Ma3ikE3rbaPq3p27F3zTsHtomLlSmTqaS4HhsWMsJwnv_5fXCT75ghEVVwghGnAazh6oB9h\">commarketing.com services products e-commerce</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHRE6QPSiFAMWPfj3TaWTJky4zoNFMJgdkS8CeY1lFSWL8UTCBGO97JQR1Rz0SiPcsLWDn_AoEZt9V5SG8UzsmSJUWoufVhtm9Rn2O-WK-xtpRNMz-z4sl0CicGF88q2VGVBhrii0M-Wht8R1GX-dS18OF2X0wWngqe3rmtSDB1fTq2FKsZTAE-wj-b4Os_a4m804d_f8ZJXMd4mtKoIATQgsATBigUVeunkpYl71FWKmTOjLXBavPTk4xZ6okK\">commarketing.com website analysis structure content purpose</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      'commarketing.com website analysis structure content purpose',\n",
      "      'commarketing.com services products e-commerce',\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='pzIUaf2XIrju4-EPk_nPsAs' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=274,\n",
      "  prompt_token_count=179,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=179\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=906,\n",
      "  tool_use_prompt_token_count=308,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=308\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=1667\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Defining Website's Purpose**\n",
      "\n",
      "I'm now researching the .NET Foundation's website. Due to access limitations, I'm relying on Google to understand the site's structure, content, functionality, and, importantly, its core purpose. My search queries, like \"dotnetfoundation.org primary purpose,\" are designed to quickly ascertain if it fits the e-commerce, mark-ops, or other classifications.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Defining Purpose**\n",
      "\n",
      "I've determined that the .NET Foundation's website is primarily focused on governance, community building, and administration for open-source projects, making the 'other' category the most fitting. The distinction from 'mark-ops' is clear, as the emphasis is on supporting the ecosystem, not marketing a specific commercial entity.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text='other'\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFoiILIt2l-uTMlXxFVovo3J5gL8_PNhA0Qi7F14EIELKiDXvt3T4QLXImPY5V5CLe4wcbDCTTpQvsGntlwp981jY6hagDz56ue7f-jlHtZaZ-NA9cSXYIpcd8zg2v_BkCeoyKZrWsCKjk4NZ7lh_jC2-efGGhXezfpYvyRq6B7IO3g1SPnHnXqHYtrg8mjdkLfT6R2vlFMHsETXQZnQTG2HPdgBhdmv5cmzB9Quz7Ne3_RJcEtn4nR6-0=\">dotnetfoundation.org primary purpose content structure</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      'dotnetfoundation.org primary purpose content structure',\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='rjIUafSDN8TnjuMPn4qVwAs' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=21,\n",
      "  prompt_token_count=178,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=178\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=845,\n",
      "  tool_use_prompt_token_count=288,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=288\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=1332\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Initiating Web Research**\n",
      "\n",
      "I'm starting by searching for \"atproperties.com\" to understand its core business. My plan is to analyze the results, looking for keywords that suggest online sales, marketing, or general informational content. I'll focus on terms related to e-commerce, marketing strategies, and company background to determine the website's primary function.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Refining Categorization Focus**\n",
      "\n",
      "I've been re-evaluating the initial e-commerce designation for this real estate website. While it lists properties, the final transaction isn't a typical online purchase. I'm leaning heavily towards \"mark-ops\" now, considering the emphasis on marketing, lead generation, and supporting agents. The site's primary function is to market the properties and brokerage services, which strongly aligns with that category.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text='mark-ops'\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQElarC7tksq820zCXjj0GmNik-R-thRcyEa8q52XinXQzUYQdWGta5pGjOPZF659mJtSPbIwaYoVleWJB5navdRYfohJ337aDFw_UlAPqSKyUcKeguINO5NRpqdvehdKNRAklHspNqmrsN7ze1wsWmaIaYb7VXZOlzy4MFRtjvbww2i-V1rLsDLWaSkVrYh-qKDCRIvTGBzFehSDM4=\">atproperties.com features</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEnEN7_t6Z8yzDzX_-nz3UYaK5_SqllDEutVkgyFbniXfjD0FpZpR0_0uX_X4xmfhs59Xa67AlFy_tHKMet0PpJPGywq_bs9mEkn8CmRG1CMzv28jzvBfHd1oI_vy1-ezu1e845T3KDchBVDQ7jJi2HZZjtWMCqBnw7gKIOK9qxEnsYzT7_SbclN8ZS9zvOHo7vKCXVjVBdl0opG2ioGioR_uGOJK53vEBMs05T\">atproperties.com website analysis purpose</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      'atproperties.com website analysis purpose',\n",
      "      'atproperties.com features',\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='tTIUaYW6LNTrjuMPoZvn8Qo' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=29,\n",
      "  prompt_token_count=178,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=178\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=697,\n",
      "  tool_use_prompt_token_count=293,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=293\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=1197\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Pinpointing Website Purpose**\n",
      "\n",
      "I'm initially focusing on Hoonigan's website structure and content. My aim is to define its core function: is it primarily for e-commerce, or does it lean towards marketing operations? I'm currently searching for product listings, shopping carts, and checkout processes to gauge its e-commerce aspects. Simultaneously, I'll be looking for sections associated with marketing, like blog and about.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Identifying Core Functionality**\n",
      "\n",
      "I've zeroed in on the website's primary function. The evidence clearly points toward e-commerce. Multiple search results highlighted the \"Shop\" call-to-action and detailed merchandise listings across various categories, solidifying the e-commerce classification.  Features like the \"Open cart\" function and product hierarchies cemented this determination. The website's e-commerce focus is irrefutable.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text='e-commerce'\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGSMhZ9_pJ_esyqOuyVNGBSThk7kuZHS0CpSB1ddaCbJ_x7F0MBn7u40W9sPIsAxbY1B4zmp3Q0jX_9duVkemMZCFeYG_XyoocEcPslOQn6tyXwPT6NmpK5PQd7sDU9Ohv4a41qILCJuJH6ctBCgo50-VHjRyNsXKkZ_-bT5P52Hg4YWpwC1_AQXyPIw_YkUsue3gHQiP18qdOiuvrTc-b60khKELkrPsfrovYpYXncgBa7Yw==\">Hoonigan website structure content functionality</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEr4D3nRa6kakaXX9xcFcT195mooT4afxuzqwMOS6beRec5s8aWr9ZqlSQY5DCB5yJQpgQH5KC8Y1P7C9EPb47svW8pr6-Jbz_qF-kzsA02-X6zmJKgymzzBdKb2UC3dvo76NjzYDJxixNIi2N7P6gYsv6Ufz25AfOtid_UAFLwmLJwFU7TXxrobKkFstd-VXcnT0bdFebP4C2CcbO0wOAYg9w9KhaB70fparEVVb2B1BMp\">Hoonigan website product listings shopping cart</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      'Hoonigan website structure content functionality',\n",
      "      'Hoonigan website product listings shopping cart',\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='uzIUafPMG7CQ4-EPgunjmQg' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=32,\n",
      "  prompt_token_count=178,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=178\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=391,\n",
      "  tool_use_prompt_token_count=311,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=311\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=912\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Categorizing the Inaccessible**\n",
      "\n",
      "I've hit a dead end with the provided URL \"nan\". It's not a valid domain, which severely limits any analysis. Given this inaccessibility, and considering I have no content or structure to work with, it appears the best classification is \"other.\" The limitations force this conclusion.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text='other'\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='vjIUaYSDEKGkjuMPnv30iAc' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  prompt_token_count=171,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=171\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=255,\n",
      "  total_token_count=426\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Assessing Website Functionality**\n",
      "\n",
      "I've initiated a search for \"Gray Matter Systems website\" and \"Gray Matter Systems\" to ascertain the company's core business focus and the website's primary emphasis. Currently, I'm analyzing the search results, specifically looking for terms that suggest e-commerce or marketing operations functionalities. Keywords like \"product listings,\" \"shopping carts,\" and \"payment gateways\" are being scrutinized, along with terms indicative of marketing operations elements.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Determining Site Functionality**\n",
      "\n",
      "I've examined Gray Matter Systems' online presence. My analysis confirms their site's core function is mark-ops. There are no product listings, shopping carts, or direct purchase pathways. Their focus is on marketing services and lead generation, as highlighted by \"Talk to our team\" prompts and a wealth of informational content.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text='mark-ops'\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEj0q_38D5EeTPNV9CAmcVUEgmmAZ3shVoo3HUX9xh2jyCjaXQnLPwvnTRZUS97n5jvImkfp9ifcmdM3Hwb7WR0C5P9sHUbFfqeOun4EGWkznOM6MVm0P9coVMaaxbD0_LGBAtCUlTGEOAAc1lJO8kqN9mO9qJ82lhrEmTJogOiwIXMj1vCL80y-HxKi6BJfrViiTmaRSbDJcUROIFuQ7wFmUckQug=\">Gray Matter Systems website purpose</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHPGdEJCKrpGfrSCwaQTrwd-Zo5w01cjvLY2aAncxVjEeKoGi_kwaupaZnt1l0Yk5qEaObc0Wlwyjm8ZWXyP-n2LVdYu_3ixfRbzbyOy8I9TCApYQPSEf4WQKQ2bPZzfQZO6I3CBLW2Tm9UCWBrd-PjHB3DOTgTwxPHQe1ISgoENJmLhbUv7kBMspDXmWjD1U1AFCG8axqBNwc4mVgMUtET4mLL1gCxLoFxdQ==\">http://www.graymattersystems.com content</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      'Gray Matter Systems website purpose',\n",
      "      'http://www.graymattersystems.com content',\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='xDIUaa7nDcLOg8UPtM3QmQU' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=33,\n",
      "  prompt_token_count=180,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=180\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=588,\n",
      "  tool_use_prompt_token_count=308,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=308\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=1109\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Defining Website's Purpose**\n",
      "\n",
      "I'm now deep into determining the core function of 1source365.com. Since I can't browse the site directly, I'm using Google to gather intel. My search queries, like \"1source365.com website analysis\" and \"what is 1source365.com,\" are yielding valuable insights.  I'm also exploring terms such as \"e-commerce or marketing\" to pinpoint its category. I'm hoping to narrow it down soon.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Pinpointing Website Content**\n",
      "\n",
      "I'm hitting a wall with the initial broad queries.  The search yielded no direct hits on the website's structure or intent. Given the name, I'm now exploring \"services offered,\" \"about us,\" and the presence of a \"shopping cart\" to infer the core focus, possibly IT, tech, or business services.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Assessing Site Visibility**\n",
      "\n",
      "I'm still struggling to find anything about the target site. The initial search yielded nothing, which is strange. I suspect it's either very new, poorly optimized for search engines, a niche B2B platform, or possibly not indexed yet. I'm going to try one more search using just the domain name to see if any directory listings or cached versions turn up.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Confirming Site Classification**\n",
      "\n",
      "I've determined that 1source365.com is definitely a \"mark-ops\" site, rather than e-commerce. It's the online face of 1 Source Occupational Health Solutions, offering B2B services, and designed to generate leads. The site emphasizes information, with sections typical of a marketing-focused presence, and no e-commerce features. It serves an organizational audience with consulting and management services.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text='mark-ops'\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEeVIHNvFI-ZKFdP1eB7JPQqbQ1-u2HkcEoFltM4Nzxssvp6J1ofOsS5f7UWDTnszTwt9o8uWxbqsmIy6G3NQPUAAydlEzhcbNxJCKQN9Wt1C89SPi9sSJNTOdo6zBCFBmxLgnfJOYn5zkd9llvjPYEHNYS39FcIAqPDJ4IxQhQm4bFzNWQr5yHs8DIFI1Hn4VQ\">1source365.com</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      '1source365.com website structure content functionality',\n",
      "      'what is 1source365.com primary purpose',\n",
      "      '1source365.com e-commerce or marketing',\n",
      "      '1source365.com services offered',\n",
      "      '1source365.com about us',\n",
      "      <... 2 more items ...>,\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='zzIUaZmlDvXY4-EPzarg6AQ' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=120,\n",
      "  prompt_token_count=181,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=181\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=758,\n",
      "  tool_use_prompt_token_count=1297,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=1297\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=2356\n",
      ") automatic_function_calling_history=[] parsed=None\n",
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=11>\n",
      ") candidates=[Candidate(\n",
      "  content=Content(\n",
      "    parts=[\n",
      "      Part(\n",
      "        text=\"\"\"**Initiating Website Analysis**\n",
      "\n",
      "I'm starting the website analysis using Google. My plan involves targeted searches to determine the site's primary function. I'll begin with broad terms like \"website analysis\" and \"purpose\" related to 1sourcebusiness.com. Then, I'll delve into searches for \"services\" and \"about us\" to assess 'mark-ops' potential, followed by an exploration for 'e-commerce' indicators via queries on shopping carts or products.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text=\"\"\"**Assessing Site Purpose**\n",
      "\n",
      "I've confirmed that \"1 Source Business Solutions\" operates as a Professional Employer Organization (PEO). My analysis revealed the site showcases services like payroll, benefits, HR compliance, and workers' compensation. Furthermore, I examined the structure and content, noting the \"About Us,\" service details, and contact features. The site's primary function is lead generation through \"Request a Quote\" and call-to-action buttons, aligning with a \"mark-ops\" classification, and not e-commerce.\n",
      "\n",
      "\n",
      "\"\"\",\n",
      "        thought=True\n",
      "      ),\n",
      "      Part(\n",
      "        text='mark-ops'\n",
      "      ),\n",
      "    ],\n",
      "    role='model'\n",
      "  ),\n",
      "  finish_reason=<FinishReason.STOP: 'STOP'>,\n",
      "  grounding_metadata=GroundingMetadata(\n",
      "    search_entry_point=SearchEntryPoint(\n",
      "      rendered_content=\"\"\"<style>\n",
      ".container {\n",
      "  align-items: center;\n",
      "  border-radius: 8px;\n",
      "  display: flex;\n",
      "  font-family: Google Sans, Roboto, sans-serif;\n",
      "  font-size: 14px;\n",
      "  line-height: 20px;\n",
      "  padding: 8px 12px;\n",
      "}\n",
      ".chip {\n",
      "  display: inline-block;\n",
      "  border: solid 1px;\n",
      "  border-radius: 16px;\n",
      "  min-width: 14px;\n",
      "  padding: 5px 16px;\n",
      "  text-align: center;\n",
      "  user-select: none;\n",
      "  margin: 0 8px;\n",
      "  -webkit-tap-highlight-color: transparent;\n",
      "}\n",
      ".carousel {\n",
      "  overflow: auto;\n",
      "  scrollbar-width: none;\n",
      "  white-space: nowrap;\n",
      "  margin-right: -12px;\n",
      "}\n",
      ".headline {\n",
      "  display: flex;\n",
      "  margin-right: 4px;\n",
      "}\n",
      ".gradient-container {\n",
      "  position: relative;\n",
      "}\n",
      ".gradient {\n",
      "  position: absolute;\n",
      "  transform: translate(3px, -9px);\n",
      "  height: 36px;\n",
      "  width: 9px;\n",
      "}\n",
      "@media (prefers-color-scheme: light) {\n",
      "  .container {\n",
      "    background-color: #fafafa;\n",
      "    box-shadow: 0 0 0 1px #0000000f;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #1f1f1f;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #ffffff;\n",
      "    border-color: #d2d2d2;\n",
      "    color: #5e5e5e;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #f2f2f2;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #d8d8d8;\n",
      "    border-color: #b6b6b6;\n",
      "  }\n",
      "  .logo-dark {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
      "  }\n",
      "}\n",
      "@media (prefers-color-scheme: dark) {\n",
      "  .container {\n",
      "    background-color: #1f1f1f;\n",
      "    box-shadow: 0 0 0 1px #ffffff26;\n",
      "  }\n",
      "  .headline-label {\n",
      "    color: #fff;\n",
      "  }\n",
      "  .chip {\n",
      "    background-color: #2c2c2c;\n",
      "    border-color: #3c4043;\n",
      "    color: #fff;\n",
      "    text-decoration: none;\n",
      "  }\n",
      "  .chip:hover {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:focus {\n",
      "    background-color: #353536;\n",
      "  }\n",
      "  .chip:active {\n",
      "    background-color: #464849;\n",
      "    border-color: #53575b;\n",
      "  }\n",
      "  .logo-light {\n",
      "    display: none;\n",
      "  }\n",
      "  .gradient {\n",
      "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
      "  }\n",
      "}\n",
      "</style>\n",
      "<div class=\"container\">\n",
      "  <div class=\"headline\">\n",
      "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
      "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
      "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
      "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
      "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
      "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
      "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
      "    </svg>\n",
      "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
      "  </div>\n",
      "  <div class=\"carousel\">\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHr_JNQmLTBFL2zm9QlSFGi9dTAgyA1VUaqktGLssdoH_rT9wY6FfUUtgv8W_L5PgAh6fDEjmdp6Egr1qt4J-6JD9bFUS9UOsLJqRj_HM6mivRmXZ3a5wiDQLrIgHbTP7kRHrHGTLAve4bvsQTINa4EAKEDHp1luEs3XcasjcooUWJbROcfeqnstcDew6L3EURaqZBmhcHX7kelLdjKv85WNatVwtnfHL4=\">1sourcebusiness.com services products</a>\n",
      "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEAfxOLt27qLbW5gx0COIQIKVIsBOBDFFN7uMDBCF9a8ogZrh9aLvM2lM0kL_zJ3KzDB36973D6oTfGYHjQEri5kCs2R5TST9ekDPFayzGgQrtxn_jrct2qNeX8UWGomKZ5cck-be_-SfjUPkNOkv8nX4M3Ay9TSjNRaRQPxlHcwezQ9NdbWeggRt9OV9L7KMz3TlEpOQk9n0stbfBUIH8GtLrMG6emy0G4TVrXQ20cJUPS8nxZwKwdPK7BESBE5A==\">1sourcebusiness.com purpose structure content functionality</a>\n",
      "  </div>\n",
      "</div>\n",
      "\"\"\"\n",
      "    ),\n",
      "    web_search_queries=[\n",
      "      '1sourcebusiness.com purpose structure content functionality',\n",
      "      '1sourcebusiness.com services products',\n",
      "    ]\n",
      "  ),\n",
      "  index=0\n",
      ")] create_time=None model_version='gemini-2.5-flash-preview-09-2025' prompt_feedback=None response_id='1jIUaYr2HPLRg8UPiPrlgAQ' usage_metadata=GenerateContentResponseUsageMetadata(\n",
      "  candidates_token_count=33,\n",
      "  prompt_token_count=179,\n",
      "  prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=179\n",
      "    ),\n",
      "  ],\n",
      "  thoughts_token_count=681,\n",
      "  tool_use_prompt_token_count=346,\n",
      "  tool_use_prompt_tokens_details=[\n",
      "    ModalityTokenCount(\n",
      "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
      "      token_count=346\n",
      "    ),\n",
      "  ],\n",
      "  total_token_count=1239\n",
      ") automatic_function_calling_history=[] parsed=None\n"
     ]
    }
   ],
   "source": [
    "df.loc[:15, \"Category_Gemini\"] = df.loc[:15, \"Website\"].apply(classify_with_gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad7a4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Website</th>\n",
       "      <th>Company Linkedin Url</th>\n",
       "      <th>Annual Revenue</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Segmented Industry</th>\n",
       "      <th>Product/ Service/ Offering</th>\n",
       "      <th>Company Country</th>\n",
       "      <th>Remarks</th>\n",
       "      <th>Category_Gemini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!n-joy Carllife</td>\n",
       "      <td>http://www.injoycarlife.com</td>\n",
       "      <td>http://www.linkedin.com/company/-n-joy-carllife</td>\n",
       "      <td>256200000</td>\n",
       "      <td>automotive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!Viva la Mama!</td>\n",
       "      <td>http://www.vivalamama.org</td>\n",
       "      <td>http://www.linkedin.com/company/-viva-la-mama-</td>\n",
       "      <td>174500000</td>\n",
       "      <td>health, wellness &amp; fitness</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the website's structure, which includes sectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Apollo\"​ Flow Controls, Manufactured by Conbr...</td>\n",
       "      <td>http://www.aalberts-ips.us</td>\n",
       "      <td>http://www.linkedin.com/company/conbraco-indus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the website exhibits the following characteris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#CaliforniansForAll College Corps</td>\n",
       "      <td>http://www.cacollegecorps.com</td>\n",
       "      <td>http://www.linkedin.com/company/californiansfo...</td>\n",
       "      <td>146000000</td>\n",
       "      <td>nonprofit organization management</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark-ops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(ISSA) International Sports Sciences Association</td>\n",
       "      <td>http://www.issaonline.com</td>\n",
       "      <td>http://www.linkedin.com/company/issaonline</td>\n",
       "      <td>100000000</td>\n",
       "      <td>government administration</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e-commerce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(RED)</td>\n",
       "      <td>http://www.red.org</td>\n",
       "      <td>http://www.linkedin.com/company/-red-</td>\n",
       "      <td>800000000</td>\n",
       "      <td>nonprofit organization management</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark-ops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(WIS) Wellbore Integrity Solutions</td>\n",
       "      <td>http://www.wellboreintegrity.com</td>\n",
       "      <td>http://www.linkedin.com/company/wellbore-integ...</td>\n",
       "      <td>319300000</td>\n",
       "      <td>oil &amp; energy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark-ops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.</td>\n",
       "      <td>http://www.asconoil.com</td>\n",
       "      <td>http://www.linkedin.com/company/oil-company-ltd</td>\n",
       "      <td>678300000</td>\n",
       "      <td>oil &amp; energy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark-ops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.Com Marketing</td>\n",
       "      <td>http://www.commarketing.com</td>\n",
       "      <td>http://www.linkedin.com/company/.com-marketing</td>\n",
       "      <td>128400000</td>\n",
       "      <td>marketing &amp; advertising</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the website at http://www.commarketing.com (wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.NET Foundation</td>\n",
       "      <td>http://www.dotnetfoundation.org</td>\n",
       "      <td>http://www.linkedin.com/company/dotnetfoundation</td>\n",
       "      <td>1000000000</td>\n",
       "      <td>information technology &amp; services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'@properties</td>\n",
       "      <td>http://www.atproperties.com</td>\n",
       "      <td>http://www.linkedin.com/company/properties</td>\n",
       "      <td>1000000000</td>\n",
       "      <td>real estate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark-ops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[HOONIGAN]</td>\n",
       "      <td>http://www.hoonigan.com</td>\n",
       "      <td>http://www.linkedin.com/company/hooniganind</td>\n",
       "      <td>1500000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e-commerce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>^exponent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.linkedin.com/company/yourexponent</td>\n",
       "      <td>560514000</td>\n",
       "      <td>internet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>| GrayMatter |</td>\n",
       "      <td>http://www.graymattersystems.com</td>\n",
       "      <td>http://www.linkedin.com/company/gray-matter-sy...</td>\n",
       "      <td>159600000</td>\n",
       "      <td>machinery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark-ops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1 Source</td>\n",
       "      <td>http://www.1source365.com</td>\n",
       "      <td>http://www.linkedin.com/company/1-source-365</td>\n",
       "      <td>100000000</td>\n",
       "      <td>management consulting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark-ops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1 Source Business Solutions</td>\n",
       "      <td>http://www.1sourcebusiness.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark-ops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100 Resilient Cities - Pioneered by the Rockef...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.linkedin.com/company/100-resilient-...</td>\n",
       "      <td>356000000</td>\n",
       "      <td>civic &amp; social organization</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100% Chiropractic Franchise</td>\n",
       "      <td>http://www.100percentchiropractic.com</td>\n",
       "      <td>http://www.linkedin.com/company/100-chiropractic</td>\n",
       "      <td>829753000</td>\n",
       "      <td>medical practice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1000 Mile Travel Group</td>\n",
       "      <td>http://www.1000miletravel.com</td>\n",
       "      <td>http://www.linkedin.com/company/1000-mile-trav...</td>\n",
       "      <td>100000000</td>\n",
       "      <td>leisure, travel &amp; tourism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10Pearls</td>\n",
       "      <td>http://www.10pearls.com</td>\n",
       "      <td>http://www.linkedin.com/company/10pearls</td>\n",
       "      <td>250000000</td>\n",
       "      <td>information technology &amp; services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Company Name  \\\n",
       "0                                     !n-joy Carllife   \n",
       "1                                      !Viva la Mama!   \n",
       "2   \"Apollo\"​ Flow Controls, Manufactured by Conbr...   \n",
       "3                   #CaliforniansForAll College Corps   \n",
       "4    (ISSA) International Sports Sciences Association   \n",
       "5                                               (RED)   \n",
       "6                  (WIS) Wellbore Integrity Solutions   \n",
       "7                                                   .   \n",
       "8                                      .Com Marketing   \n",
       "9                                     .NET Foundation   \n",
       "10                                       '@properties   \n",
       "11                                         [HOONIGAN]   \n",
       "12                                          ^exponent   \n",
       "13                                     | GrayMatter |   \n",
       "14                                           1 Source   \n",
       "15                        1 Source Business Solutions   \n",
       "16  100 Resilient Cities - Pioneered by the Rockef...   \n",
       "17                        100% Chiropractic Franchise   \n",
       "18                             1000 Mile Travel Group   \n",
       "19                                           10Pearls   \n",
       "\n",
       "                                  Website  \\\n",
       "0             http://www.injoycarlife.com   \n",
       "1               http://www.vivalamama.org   \n",
       "2              http://www.aalberts-ips.us   \n",
       "3           http://www.cacollegecorps.com   \n",
       "4               http://www.issaonline.com   \n",
       "5                      http://www.red.org   \n",
       "6        http://www.wellboreintegrity.com   \n",
       "7                 http://www.asconoil.com   \n",
       "8             http://www.commarketing.com   \n",
       "9         http://www.dotnetfoundation.org   \n",
       "10            http://www.atproperties.com   \n",
       "11                http://www.hoonigan.com   \n",
       "12                                    NaN   \n",
       "13       http://www.graymattersystems.com   \n",
       "14              http://www.1source365.com   \n",
       "15         http://www.1sourcebusiness.com   \n",
       "16                                    NaN   \n",
       "17  http://www.100percentchiropractic.com   \n",
       "18          http://www.1000miletravel.com   \n",
       "19                http://www.10pearls.com   \n",
       "\n",
       "                                 Company Linkedin Url Annual Revenue  \\\n",
       "0     http://www.linkedin.com/company/-n-joy-carllife      256200000   \n",
       "1      http://www.linkedin.com/company/-viva-la-mama-      174500000   \n",
       "2   http://www.linkedin.com/company/conbraco-indus...            NaN   \n",
       "3   http://www.linkedin.com/company/californiansfo...      146000000   \n",
       "4          http://www.linkedin.com/company/issaonline      100000000   \n",
       "5               http://www.linkedin.com/company/-red-      800000000   \n",
       "6   http://www.linkedin.com/company/wellbore-integ...      319300000   \n",
       "7     http://www.linkedin.com/company/oil-company-ltd      678300000   \n",
       "8      http://www.linkedin.com/company/.com-marketing      128400000   \n",
       "9    http://www.linkedin.com/company/dotnetfoundation     1000000000   \n",
       "10         http://www.linkedin.com/company/properties     1000000000   \n",
       "11        http://www.linkedin.com/company/hooniganind     1500000000   \n",
       "12       http://www.linkedin.com/company/yourexponent      560514000   \n",
       "13  http://www.linkedin.com/company/gray-matter-sy...      159600000   \n",
       "14       http://www.linkedin.com/company/1-source-365      100000000   \n",
       "15                                                NaN      154100000   \n",
       "16  http://www.linkedin.com/company/100-resilient-...      356000000   \n",
       "17   http://www.linkedin.com/company/100-chiropractic      829753000   \n",
       "18  http://www.linkedin.com/company/1000-mile-trav...      100000000   \n",
       "19           http://www.linkedin.com/company/10pearls      250000000   \n",
       "\n",
       "                             Industry  Segmented Industry   \\\n",
       "0                          automotive                  NaN   \n",
       "1          health, wellness & fitness                  NaN   \n",
       "2                                 NaN                  NaN   \n",
       "3   nonprofit organization management                  NaN   \n",
       "4           government administration                  NaN   \n",
       "5   nonprofit organization management                  NaN   \n",
       "6                        oil & energy                  NaN   \n",
       "7                        oil & energy                  NaN   \n",
       "8             marketing & advertising                  NaN   \n",
       "9   information technology & services                  NaN   \n",
       "10                        real estate                  NaN   \n",
       "11                                NaN                  NaN   \n",
       "12                           internet                  NaN   \n",
       "13                          machinery                  NaN   \n",
       "14              management consulting                  NaN   \n",
       "15                                NaN                  NaN   \n",
       "16        civic & social organization                  NaN   \n",
       "17                   medical practice                  NaN   \n",
       "18          leisure, travel & tourism                  NaN   \n",
       "19  information technology & services                  NaN   \n",
       "\n",
       "    Product/ Service/ Offering Company Country Remarks  \\\n",
       "0                          NaN   United States     NaN   \n",
       "1                          NaN   United States     NaN   \n",
       "2                          NaN   United States     NaN   \n",
       "3                          NaN   United States     NaN   \n",
       "4                          NaN   United States     NaN   \n",
       "5                          NaN   United States     NaN   \n",
       "6                          NaN   United States     NaN   \n",
       "7                          NaN   United States     NaN   \n",
       "8                          NaN   United States     NaN   \n",
       "9                          NaN   United States     NaN   \n",
       "10                         NaN   United States     NaN   \n",
       "11                         NaN   United States     NaN   \n",
       "12                         NaN   United States     NaN   \n",
       "13                         NaN   United States     NaN   \n",
       "14                         NaN   United States     NaN   \n",
       "15                         NaN   United States     NaN   \n",
       "16                         NaN   United States     NaN   \n",
       "17                         NaN   United States     NaN   \n",
       "18                         NaN   United States     NaN   \n",
       "19                         NaN   United States     NaN   \n",
       "\n",
       "                                      Category_Gemini  \n",
       "0                                               other  \n",
       "1   the website's structure, which includes sectio...  \n",
       "2   the website exhibits the following characteris...  \n",
       "3                                            mark-ops  \n",
       "4                                          e-commerce  \n",
       "5                                            mark-ops  \n",
       "6                                            mark-ops  \n",
       "7                                            mark-ops  \n",
       "8   the website at http://www.commarketing.com (wh...  \n",
       "9                                               other  \n",
       "10                                           mark-ops  \n",
       "11                                         e-commerce  \n",
       "12                                              other  \n",
       "13                                           mark-ops  \n",
       "14                                           mark-ops  \n",
       "15                                           mark-ops  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c73012c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting compressed-tensors\n",
      "  Using cached compressed_tensors-0.12.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting torch>=1.7.0 (from compressed-tensors)\n",
      "  Downloading torch-2.9.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Collecting transformers (from compressed-tensors)\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting pydantic>=2.0 (from compressed-tensors)\n",
      "  Using cached pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting loguru (from compressed-tensors)\n",
      "  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->compressed-tensors)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.0->compressed-tensors)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-extensions>=4.14.1 (from pydantic>=2.0->compressed-tensors)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic>=2.0->compressed-tensors)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting filelock (from torch>=1.7.0->compressed-tensors)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.7.0->compressed-tensors)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=1.7.0->compressed-tensors)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.7.0->compressed-tensors)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch>=1.7.0->compressed-tensors)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setuptools (from torch>=1.7.0->compressed-tensors)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.7.0->compressed-tensors)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.7.0->compressed-tensors)\n",
      "  Downloading markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting colorama>=0.3.4 (from loguru->compressed-tensors)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru->compressed-tensors)\n",
      "  Using cached win32_setctime-1.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers->compressed-tensors)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.17 (from transformers->compressed-tensors)\n",
      "  Downloading numpy-2.3.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting packaging>=20.0 (from transformers->compressed-tensors)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers->compressed-tensors)\n",
      "  Downloading pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers->compressed-tensors)\n",
      "  Using cached regex-2025.11.3-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers->compressed-tensors)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers->compressed-tensors)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers->compressed-tensors)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers->compressed-tensors)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers->compressed-tensors)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers->compressed-tensors)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers->compressed-tensors)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers->compressed-tensors)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached compressed_tensors-0.12.2-py3-none-any.whl (183 kB)\n",
      "Using cached pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.3/2.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 5.6 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading torch-2.9.0-cp312-cp312-win_amd64.whl (109.3 MB)\n",
      "   ---------------------------------------- 0.0/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/109.3 MB 6.7 MB/s eta 0:00:17\n",
      "    --------------------------------------- 2.4/109.3 MB 5.8 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 5.2/109.3 MB 8.8 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 5.8/109.3 MB 6.9 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 6.3/109.3 MB 6.0 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 9.7/109.3 MB 7.8 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 13.6/109.3 MB 9.4 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 17.8/109.3 MB 10.7 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 22.0/109.3 MB 11.7 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 26.0/109.3 MB 12.4 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 29.6/109.3 MB 12.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 33.8/109.3 MB 13.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 37.2/109.3 MB 13.7 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 40.1/109.3 MB 13.6 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 45.4/109.3 MB 14.4 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 49.8/109.3 MB 14.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 54.8/109.3 MB 15.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 58.7/109.3 MB 15.5 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 63.4/109.3 MB 15.9 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 68.7/109.3 MB 16.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 74.4/109.3 MB 16.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 80.0/109.3 MB 17.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 84.9/109.3 MB 17.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 88.3/109.3 MB 17.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 93.1/109.3 MB 17.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 98.0/109.3 MB 17.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 100.9/109.3 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 104.9/109.3 MB 17.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  109.1/109.3 MB 17.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  109.1/109.3 MB 17.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 109.3/109.3 MB 17.1 MB/s eta 0:00:00\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached win32_setctime-1.2.0-py3-none-any.whl (4.1 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Downloading numpy-2.3.4-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.6/12.8 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.1/12.8 MB 17.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.3/12.8 MB 18.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 17.4 MB/s eta 0:00:00\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
      "Using cached regex-2025.11.3-cp312-cp312-win_amd64.whl (277 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: mpmath, win32-setctime, urllib3, typing-extensions, sympy, setuptools, safetensors, regex, pyyaml, packaging, numpy, networkx, MarkupSafe, idna, fsspec, filelock, colorama, charset_normalizer, certifi, annotated-types, typing-inspection, tqdm, requests, pydantic-core, loguru, jinja2, torch, pydantic, huggingface-hub, tokenizers, transformers, compressed-tensors\n",
      "\n",
      "  Attempting uninstall: mpmath\n",
      "\n",
      "    Found existing installation: mpmath 1.3.0\n",
      "\n",
      "    Uninstalling mpmath-1.3.0:\n",
      "\n",
      "      Successfully uninstalled mpmath-1.3.0\n",
      "\n",
      "   ----------------------------------------  0/32 [mpmath]\n",
      "   ----------------------------------------  0/32 [mpmath]\n",
      "   ----------------------------------------  0/32 [mpmath]\n",
      "   ----------------------------------------  0/32 [mpmath]\n",
      "   ----------------------------------------  0/32 [mpmath]\n",
      "   ----------------------------------------  0/32 [mpmath]\n",
      "   ----------------------------------------  0/32 [mpmath]\n",
      "   ----------------------------------------  0/32 [mpmath]\n",
      "  Attempting uninstall: win32-setctime\n",
      "   ----------------------------------------  0/32 [mpmath]\n",
      "    Found existing installation: win32_setctime 1.2.0\n",
      "   ----------------------------------------  0/32 [mpmath]\n",
      "    Uninstalling win32_setctime-1.2.0:\n",
      "   ----------------------------------------  0/32 [mpmath]\n",
      "      Successfully uninstalled win32_setctime-1.2.0\n",
      "   ----------------------------------------  0/32 [mpmath]\n",
      "   - --------------------------------------  1/32 [win32-setctime]\n",
      "  Attempting uninstall: urllib3\n",
      "   - --------------------------------------  1/32 [win32-setctime]\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "   - --------------------------------------  1/32 [win32-setctime]\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "   - --------------------------------------  1/32 [win32-setctime]\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "   - --------------------------------------  1/32 [win32-setctime]\n",
      "   -- -------------------------------------  2/32 [urllib3]\n",
      "   -- -------------------------------------  2/32 [urllib3]\n",
      "   -- -------------------------------------  2/32 [urllib3]\n",
      "  Attempting uninstall: typing-extensions\n",
      "   -- -------------------------------------  2/32 [urllib3]\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "   -- -------------------------------------  2/32 [urllib3]\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "   -- -------------------------------------  2/32 [urllib3]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "  Attempting uninstall: sympy\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "    Found existing installation: sympy 1.13.3\n",
      "   --- ------------------------------------  3/32 [typing-extensions]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "    Uninstalling sympy-1.13.3:\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "  Attempting uninstall: setuptools\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "    Found existing installation: setuptools 75.6.0\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "    Uninstalling setuptools-75.6.0:\n",
      "   ----- ----------------------------------  4/32 [sympy]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "      Successfully uninstalled setuptools-75.6.0\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "  Attempting uninstall: safetensors\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "    Found existing installation: safetensors 0.6.2\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "    Uninstalling safetensors-0.6.2:\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "      Successfully uninstalled safetensors-0.6.2\n",
      "   ------ ---------------------------------  5/32 [setuptools]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "  Attempting uninstall: regex\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "    Found existing installation: regex 2025.11.3\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "    Uninstalling regex-2025.11.3:\n",
      "   ------- --------------------------------  6/32 [safetensors]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "      Successfully uninstalled regex-2025.11.3\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "  Attempting uninstall: pyyaml\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "   -------- -------------------------------  7/32 [regex]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "  Attempting uninstall: packaging\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "    Found existing installation: packaging 24.1\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "    Uninstalling packaging-24.1:\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "      Successfully uninstalled packaging-24.1\n",
      "   ---------- -----------------------------  8/32 [pyyaml]\n",
      "   ----------- ----------------------------  9/32 [packaging]\n",
      "   ----------- ----------------------------  9/32 [packaging]\n",
      "  Attempting uninstall: numpy\n",
      "   ----------- ----------------------------  9/32 [packaging]\n",
      "    Found existing installation: numpy 2.1.3\n",
      "   ----------- ----------------------------  9/32 [packaging]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "    Uninstalling numpy-2.1.3:\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "  Attempting uninstall: networkx\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "    Found existing installation: networkx 3.4.2\n",
      "   ------------ --------------------------- 10/32 [numpy]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "    Uninstalling networkx-3.4.2:\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "      Successfully uninstalled networkx-3.4.2\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "  Attempting uninstall: MarkupSafe\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "   ------------- -------------------------- 11/32 [networkx]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "  Attempting uninstall: idna\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "    Found existing installation: idna 3.10\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "    Uninstalling idna-3.10:\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "      Successfully uninstalled idna-3.10\n",
      "   --------------- ------------------------ 12/32 [MarkupSafe]\n",
      "   ---------------- ----------------------- 13/32 [idna]\n",
      "  Attempting uninstall: fsspec\n",
      "   ---------------- ----------------------- 13/32 [idna]\n",
      "   ----------------- ---------------------- 14/32 [fsspec]\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "   ----------------- ---------------------- 14/32 [fsspec]\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "   ----------------- ---------------------- 14/32 [fsspec]\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "   ----------------- ---------------------- 14/32 [fsspec]\n",
      "   ----------------- ---------------------- 14/32 [fsspec]\n",
      "   ----------------- ---------------------- 14/32 [fsspec]\n",
      "   ----------------- ---------------------- 14/32 [fsspec]\n",
      "   ----------------- ---------------------- 14/32 [fsspec]\n",
      "   ----------------- ---------------------- 14/32 [fsspec]\n",
      "  Attempting uninstall: filelock\n",
      "   ----------------- ---------------------- 14/32 [fsspec]\n",
      "    Found existing installation: filelock 3.16.1\n",
      "   ----------------- ---------------------- 14/32 [fsspec]\n",
      "   ------------------ --------------------- 15/32 [filelock]\n",
      "    Uninstalling filelock-3.16.1:\n",
      "   ------------------ --------------------- 15/32 [filelock]\n",
      "      Successfully uninstalled filelock-3.16.1\n",
      "   ------------------ --------------------- 15/32 [filelock]\n",
      "  Attempting uninstall: colorama\n",
      "   ------------------ --------------------- 15/32 [filelock]\n",
      "    Found existing installation: colorama 0.4.6\n",
      "   ------------------ --------------------- 15/32 [filelock]\n",
      "   -------------------- ------------------- 16/32 [colorama]\n",
      "    Uninstalling colorama-0.4.6:\n",
      "   -------------------- ------------------- 16/32 [colorama]\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "   -------------------- ------------------- 16/32 [colorama]\n",
      "   -------------------- ------------------- 16/32 [colorama]\n",
      "  Attempting uninstall: charset_normalizer\n",
      "   -------------------- ------------------- 16/32 [colorama]\n",
      "    Found existing installation: charset-normalizer 3.4.0\n",
      "   -------------------- ------------------- 16/32 [colorama]\n",
      "    Uninstalling charset-normalizer-3.4.0:\n",
      "   -------------------- ------------------- 16/32 [colorama]\n",
      "      Successfully uninstalled charset-normalizer-3.4.0\n",
      "   -------------------- ------------------- 16/32 [colorama]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "  Attempting uninstall: certifi\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "    Found existing installation: certifi 2024.8.30\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "    Uninstalling certifi-2024.8.30:\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "      Successfully uninstalled certifi-2024.8.30\n",
      "   --------------------- ------------------ 17/32 [charset_normalizer]\n",
      "   ---------------------- ----------------- 18/32 [certifi]\n",
      "  Attempting uninstall: annotated-types\n",
      "   ---------------------- ----------------- 18/32 [certifi]\n",
      "    Found existing installation: annotated-types 0.7.0\n",
      "   ---------------------- ----------------- 18/32 [certifi]\n",
      "    Uninstalling annotated-types-0.7.0:\n",
      "   ---------------------- ----------------- 18/32 [certifi]\n",
      "      Successfully uninstalled annotated-types-0.7.0\n",
      "   ---------------------- ----------------- 18/32 [certifi]\n",
      "   ------------------------- -------------- 20/32 [typing-inspection]\n",
      "  Attempting uninstall: tqdm\n",
      "   ------------------------- -------------- 20/32 [typing-inspection]\n",
      "    Found existing installation: tqdm 4.66.6\n",
      "   ------------------------- -------------- 20/32 [typing-inspection]\n",
      "    Uninstalling tqdm-4.66.6:\n",
      "   ------------------------- -------------- 20/32 [typing-inspection]\n",
      "      Successfully uninstalled tqdm-4.66.6\n",
      "   ------------------------- -------------- 20/32 [typing-inspection]\n",
      "   -------------------------- ------------- 21/32 [tqdm]\n",
      "   -------------------------- ------------- 21/32 [tqdm]\n",
      "   -------------------------- ------------- 21/32 [tqdm]\n",
      "  Attempting uninstall: requests\n",
      "   -------------------------- ------------- 21/32 [tqdm]\n",
      "    Found existing installation: requests 2.32.3\n",
      "   -------------------------- ------------- 21/32 [tqdm]\n",
      "    Uninstalling requests-2.32.3:\n",
      "   -------------------------- ------------- 21/32 [tqdm]\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "   -------------------------- ------------- 21/32 [tqdm]\n",
      "   --------------------------- ------------ 22/32 [requests]\n",
      "   --------------------------- ------------ 22/32 [requests]\n",
      "  Attempting uninstall: pydantic-core\n",
      "   --------------------------- ------------ 22/32 [requests]\n",
      "    Found existing installation: pydantic_core 2.27.2\n",
      "   --------------------------- ------------ 22/32 [requests]\n",
      "    Uninstalling pydantic_core-2.27.2:\n",
      "   --------------------------- ------------ 22/32 [requests]\n",
      "      Successfully uninstalled pydantic_core-2.27.2\n",
      "   --------------------------- ------------ 22/32 [requests]\n",
      "   ---------------------------- ----------- 23/32 [pydantic-core]\n",
      "  Attempting uninstall: loguru\n",
      "   ---------------------------- ----------- 23/32 [pydantic-core]\n",
      "    Found existing installation: loguru 0.7.3\n",
      "   ---------------------------- ----------- 23/32 [pydantic-core]\n",
      "    Uninstalling loguru-0.7.3:\n",
      "   ---------------------------- ----------- 23/32 [pydantic-core]\n",
      "      Successfully uninstalled loguru-0.7.3\n",
      "   ---------------------------- ----------- 23/32 [pydantic-core]\n",
      "   ------------------------------ --------- 24/32 [loguru]\n",
      "   ------------------------------ --------- 24/32 [loguru]\n",
      "  Attempting uninstall: jinja2\n",
      "   ------------------------------ --------- 24/32 [loguru]\n",
      "    Found existing installation: Jinja2 3.1.4\n",
      "   ------------------------------ --------- 24/32 [loguru]\n",
      "    Uninstalling Jinja2-3.1.4:\n",
      "   ------------------------------ --------- 24/32 [loguru]\n",
      "      Successfully uninstalled Jinja2-3.1.4\n",
      "   ------------------------------ --------- 24/32 [loguru]\n",
      "   ------------------------------- -------- 25/32 [jinja2]\n",
      "   ------------------------------- -------- 25/32 [jinja2]\n",
      "   ------------------------------- -------- 25/32 [jinja2]\n",
      "  Attempting uninstall: torch\n",
      "   ------------------------------- -------- 25/32 [jinja2]\n",
      "    Found existing installation: torch 2.2.0\n",
      "   ------------------------------- -------- 25/32 [jinja2]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "    Uninstalling torch-2.2.0:\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "      Successfully uninstalled torch-2.2.0\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "  Attempting uninstall: pydantic\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "    Found existing installation: pydantic 2.10.4\n",
      "   -------------------------------- ------- 26/32 [torch]\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "    Uninstalling pydantic-2.10.4:\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "      Successfully uninstalled pydantic-2.10.4\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "  Attempting uninstall: huggingface-hub\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "    Found existing installation: huggingface-hub 0.36.0\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "    Uninstalling huggingface-hub-0.36.0:\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "      Successfully uninstalled huggingface-hub-0.36.0\n",
      "   --------------------------------- ------ 27/32 [pydantic]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "  Attempting uninstall: tokenizers\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "    Found existing installation: tokenizers 0.22.1\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "    Uninstalling tokenizers-0.22.1:\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "      Successfully uninstalled tokenizers-0.22.1\n",
      "   ----------------------------------- ---- 28/32 [huggingface-hub]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "  Attempting uninstall: transformers\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "    Found existing installation: transformers 4.57.1\n",
      "   ------------------------------------ --- 29/32 [tokenizers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "    Uninstalling transformers-4.57.1:\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "      Successfully uninstalled transformers-4.57.1\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "  Attempting uninstall: compressed-tensors\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "    Found existing installation: compressed-tensors 0.12.2\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "    Uninstalling compressed-tensors-0.12.2:\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "      Successfully uninstalled compressed-tensors-0.12.2\n",
      "   ------------------------------------- -- 30/32 [transformers]\n",
      "   -------------------------------------- - 31/32 [compressed-tensors]\n",
      "   -------------------------------------- - 31/32 [compressed-tensors]\n",
      "   -------------------------------------- - 31/32 [compressed-tensors]\n",
      "   -------------------------------------- - 31/32 [compressed-tensors]\n",
      "   -------------------------------------- - 31/32 [compressed-tensors]\n",
      "   -------------------------------------- - 31/32 [compressed-tensors]\n",
      "   -------------------------------------- - 31/32 [compressed-tensors]\n",
      "   ---------------------------------------- 32/32 [compressed-tensors]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 annotated-types-0.7.0 certifi-2025.11.12 charset_normalizer-3.4.4 colorama-0.4.6 compressed-tensors-0.12.2 filelock-3.20.0 fsspec-2025.10.0 huggingface-hub-0.36.0 idna-3.11 jinja2-3.1.6 loguru-0.7.3 mpmath-1.3.0 networkx-3.5 numpy-2.3.4 packaging-25.0 pydantic-2.12.4 pydantic-core-2.41.5 pyyaml-6.0.3 regex-2025.11.3 requests-2.32.5 safetensors-0.6.2 setuptools-80.9.0 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.0 tqdm-4.67.1 transformers-4.57.1 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.5.0 win32-setctime-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\KamranImtiyaz\\AppData\\Roaming\\Python\\Python312\\site-packages\\~afetensors'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\KamranImtiyaz\\AppData\\Roaming\\Python\\Python312\\site-packages\\~egex'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\KamranImtiyaz\\AppData\\Roaming\\Python\\Python312\\site-packages\\~aml'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\KamranImtiyaz\\AppData\\Roaming\\Python\\Python312\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\KamranImtiyaz\\AppData\\Roaming\\Python\\Python312\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\KamranImtiyaz\\AppData\\Roaming\\Python\\Python312\\site-packages\\~arkupsafe'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\KamranImtiyaz\\AppData\\Roaming\\Python\\Python312\\site-packages\\~harset_normalizer'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\KamranImtiyaz\\AppData\\Roaming\\Python\\Python312\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\KamranImtiyaz\\AppData\\Roaming\\Python\\Python312\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-core 0.3.28 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!\"C:\\Program Files\\Python312\\python.exe\" -m pip install compressed-tensors --upgrade --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df2ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hf import hf_api_key\n",
    "import os \n",
    "os.environ[\"HF_API_KEY\"] = hf_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61b93c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type kimi_k2 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "compressed_tensors is not installed and is required for compressed-tensors quantization. Please install it with `pip install compressed-tensors`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoonshotai/Kimi-K2-Thinking\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Define classification function\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_with_kimi\u001b[39m(url):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\auto\\auto_factory.py:597\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m         model_class\u001b[38;5;241m.\u001b[39mregister_for_auto_class(auto_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    596\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m add_generation_mixin_to_remote_model(model_class)\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping:\n\u001b[0;32m    601\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\modeling_utils.py:277\u001b[0m, in \u001b[0;36mrestore_default_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\modeling_utils.py:4881\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   4872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transformers_explicit_filename\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[0;32m   4873\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4874\u001b[0m     ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transformers_explicit_filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors.index.json\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   4875\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4876\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe transformers file in the config seems to be incorrect: it is neither a safetensors file \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4877\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(*.safetensors) nor a safetensors index file (*.safetensors.index.json): \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4878\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransformers_explicit_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4879\u001b[0m         )\n\u001b[1;32m-> 4881\u001b[0m hf_quantizer, config, dtype, device_map \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_quantizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_agent\u001b[49m\n\u001b[0;32m   4883\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4886\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4887\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot combine Quantization and loading a model from a GGUF file, try again by making sure you did not passed a `quantization_config` or that you did not load a quantized model from the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4888\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\quantizers\\auto.py:305\u001b[0m, in \u001b[0;36mget_hf_quantizer\u001b[1;34m(config, quantization_config, dtype, from_tf, from_flax, device_map, weights_only, user_agent)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_quantized \u001b[38;5;129;01mor\u001b[39;00m quantization_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pre_quantized:\n\u001b[1;32m--> 305\u001b[0m         config\u001b[38;5;241m.\u001b[39mquantization_config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoHfQuantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_quantization_configs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m         config\u001b[38;5;241m.\u001b[39mquantization_config \u001b[38;5;241m=\u001b[39m quantization_config\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\quantizers\\auto.py:214\u001b[0m, in \u001b[0;36mAutoHfQuantizer.merge_quantization_configs\u001b[1;34m(cls, quantization_config, quantization_config_from_args)\u001b[0m\n\u001b[0;32m    212\u001b[0m         quantization_config \u001b[38;5;241m=\u001b[39m AutoRoundConfig\u001b[38;5;241m.\u001b[39mfrom_dict(quantization_config)\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 214\u001b[0m         quantization_config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoQuantizationConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    217\u001b[0m     quantization_config_from_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m quantization_config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m quantization_config_from_args\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    219\u001b[0m ):\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model is quantized with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquantization_config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but you are passing a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquantization_config_from_args\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m config. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease make sure to pass the same quantization config class to `from_pretrained` with different loading attributes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\quantizers\\auto.py:140\u001b[0m, in \u001b[0;36mAutoQuantizationConfig.from_dict\u001b[1;34m(cls, quantization_config_dict)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown quantization type, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquant_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - supported types are:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(AUTO_QUANTIZER_MAPPING\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    139\u001b[0m target_cls \u001b[38;5;241m=\u001b[39m AUTO_QUANTIZATION_CONFIG_MAPPING[quant_method]\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantization_config_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\quantization_config.py:1398\u001b[0m, in \u001b[0;36mCompressedTensorsConfig.from_dict\u001b[1;34m(cls, config_dict, return_unused_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m   1393\u001b[0m     config_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m   1394\u001b[0m         sparsity_config\u001b[38;5;241m=\u001b[39mconfig_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparsity_config\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1395\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1396\u001b[0m     )\n\u001b[1;32m-> 1398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\quantization_config.py:122\u001b[0m, in \u001b[0;36mQuantizationConfigMixin.from_dict\u001b[1;34m(cls, config_dict, return_unused_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_dict\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config_dict, return_unused_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m    Instantiates a [`QuantizationConfigMixin`] from a Python dictionary of parameters.\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m        [`QuantizationConfigMixin`]: The configuration object instantiated from those parameters.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     to_remove \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\utils\\quantization_config.py:1328\u001b[0m, in \u001b[0;36mCompressedTensorsConfig.__init__\u001b[1;34m(self, config_groups, format, quantization_status, kv_cache_scheme, global_compression_ratio, ignore, sparsity_config, quant_method, run_compressed, **kwargs)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcompressed_tensors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantizationConfig\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1328\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m   1329\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompressed_tensors is not installed and is required for compressed-tensors quantization. Please install it with `pip install compressed-tensors`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1330\u001b[0m     )\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantization_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparsity_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: compressed_tensors is not installed and is required for compressed-tensors quantization. Please install it with `pip install compressed-tensors`."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import torch\n",
    "import re\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"moonshotai/Kimi-K2-Thinking\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, dtype=\"auto\",device_map=\"auto\")\n",
    "\n",
    "# Define classification function\n",
    "def classify_with_kimi(url):\n",
    "    prompt = (\n",
    "        f\"Analyze the website at {url}. \"\n",
    "        \"Evaluate its structure, content, and functionality to determine its primary purpose. \"\n",
    "        \"Classify the website into one of the following categories: \"\n",
    "        \"1) 'e-commerce' — if it primarily enables online sales or transactions and includes features such as product listings, shopping carts, checkout or payment gateways, customer accounts, promotional offers, or order tracking. \"\n",
    "        \"2) 'mark-ops' — if it focuses on marketing, branding, lead generation, or corporate communications, typically featuring sections like 'About Us', 'Services', 'Case Studies', 'Blog', or 'Contact Us' but without direct purchase options. \"\n",
    "        \"3) 'other' — if it does not clearly fit into either category. \"\n",
    "        \"Respond with only one of the following labels: 'e-commerce', 'mark-ops', or 'other'.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=100,\n",
    "                temperature=0.3,\n",
    "                do_sample=True,\n",
    "            )\n",
    "        result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        match = re.search(r\"(e-commerce|mark-ops|other)\", result.lower())\n",
    "        return match.group(1) if match else \"other\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {e}\")\n",
    "        return \"error\"\n",
    "\n",
    "# Example: Load your DataFrame\n",
    "# df = pd.read_csv(\"websites.csv\")\n",
    "\n",
    "# Run classification on first 15 rows\n",
    "df.loc[:15, \"Category_Kimi\"] = df.loc[:15, \"Website\"].apply(classify_with_kimi)\n",
    "\n",
    "# Save results if you want\n",
    "# df.to_csv(\"classified_websites.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadcd119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5533c344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Set the OPENAI_API_KEY environment variable and re-run.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KamranImtiyaz\\AppData\\Roaming\\Python\\Python314\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import threading\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "from Open import OPEN_AI_API_KEY\n",
    "\n",
    "# pip install openai requests pandas\n",
    "import openai\n",
    "\n",
    "# ========================================================\n",
    "# 0. Configuration (edit as needed)\n",
    "# ========================================================\n",
    "OPENAI_API_KEY = os.environ.get(\"OPEN_AI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"ERROR: Set the OPENAI_API_KEY environment variable and re-run.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "MODEL = \"gpt-4o-mini\"   # function-calling capable model in this flow\n",
    "CSV_PATH = r\"C:\\Users\\KamranImtiyaz\\OneDrive - MinoriLabs\\Desktop\\Agent\\New Ecom - Industry Segmentation _ Oct2025(WIP).csv\"\n",
    "OUTPUT_PATH = r\"classified_output.csv\"\n",
    "\n",
    "# ========================================================\n",
    "# 0b. Timeout wrapper (Windows-compatible)\n",
    "# ========================================================\n",
    "def run_with_timeout(func, args=(), kwargs=None, timeout=10):\n",
    "    if kwargs is None:\n",
    "        kwargs = {}\n",
    "    result = [None]\n",
    "    exception = [None]\n",
    "\n",
    "    def target():\n",
    "        try:\n",
    "            result[0] = func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            exception[0] = e\n",
    "\n",
    "    thread = threading.Thread(target=target, daemon=True)\n",
    "    thread.start()\n",
    "    thread.join(timeout)\n",
    "\n",
    "    if thread.is_alive():\n",
    "        return \"TIMEOUT\"\n",
    "    if exception[0]:\n",
    "        raise exception[0]\n",
    "    return result[0]\n",
    "\n",
    "# ========================================================\n",
    "# 1. Load CSV (preserve previous run if exists)\n",
    "# ========================================================\n",
    "if os.path.exists(OUTPUT_PATH):\n",
    "    print(f\"Found existing output file -> loading from {OUTPUT_PATH} to preserve previous labels.\")\n",
    "    df = pd.read_csv(OUTPUT_PATH)\n",
    "else:\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "if \"Category_Gemini\" not in df.columns:\n",
    "    df[\"Category_Gemini\"] = \"\"\n",
    "\n",
    "# normalize column values to be robust for skip logic\n",
    "df[\"Category_Gemini\"] = df[\"Category_Gemini\"].astype(str).str.strip()\n",
    "df[\"Category_Gemini\"].replace({\"nan\": \"\", \"NaN\": \"\", \"None\": \"\", \"none\": \"\"}, inplace=True)\n",
    "\n",
    "# ========================================================\n",
    "# 2. Manual Start Options (edit MANUAL_START / MANUAL_ROW as needed)\n",
    "# ========================================================\n",
    "MANUAL_START = True\n",
    "MANUAL_ROW = 286\n",
    "\n",
    "if MANUAL_START:\n",
    "    start_index = MANUAL_ROW\n",
    "    print(f\"Manual start enabled → Starting at row {start_index}\")\n",
    "else:\n",
    "    empty_mask = df[\"Category_Gemini\"].isna() | (df[\"Category_Gemini\"].astype(str).str.strip() == \"\")\n",
    "    if empty_mask.any():\n",
    "        # idxmax returns first True index because booleans cast to ints; safe here\n",
    "        start_index = empty_mask.idxmax()\n",
    "    else:\n",
    "        start_index = None\n",
    "    print(f\"Auto-resume enabled → Starting at first unclassified row: {start_index}\")\n",
    "\n",
    "if start_index is None or pd.isna(start_index):\n",
    "    print(\"✔ All rows already classified!\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# ========================================================\n",
    "# 3. Simple \"tool\" implementations\n",
    "#    - perform_search(q): returns short aggregated snippets from Google search results\n",
    "#      (lightweight, scraping Google SERP HTML; not a heavy production search integration)\n",
    "# ========================================================\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (compatible; classification-bot/1.0)\"}\n",
    "\n",
    "def perform_search(query, num_results=5):\n",
    "    \"\"\"\n",
    "    Lightweight scraping of Google results page. Returns a concatenated string of titles+snippets.\n",
    "    NOTE: This is a basic approach for small scale use. For production use a proper search API (SerpAPI, Bing, GCS).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not query or str(query).strip() == \"\":\n",
    "            return \"NO_QUERY\"\n",
    "        # Use simple Google query URL (may be rate-limited or blocked). Keep it conservative.\n",
    "        url = \"https://www.google.com/search\"\n",
    "        params = {\"q\": query, \"num\": num_results, \"hl\": \"en\"}\n",
    "        r = requests.get(url, params=params, headers=HEADERS, timeout=10)\n",
    "        if r.status_code != 200:\n",
    "            return f\"ERROR_HTTP_{r.status_code}\"\n",
    "        html = r.text\n",
    "        # Very small, robust parsing: get lines that contain \"class=\\\"BNeawe vvjwJb AP7Wnd\\\"\" (titles) or \"class=\\\"BNeawe s3v9rd AP7Wnd\\\"\" (snippets)\n",
    "        # Google markup changes frequently; fallback to returning raw HTML trimmed.\n",
    "        snippets = []\n",
    "        # naive split searching for typical snippet markers:\n",
    "        for token in ['<div class=\"BNeawe vvjwJb AP7Wnd\">', '<div class=\"BNeawe s3v9rd AP7Wnd\">', '<div class=\"BNeawe s3v9rd AP7Wnd\">']:\n",
    "            if token in html:\n",
    "                parts = html.split(token)[1: num_results*2 + 1]\n",
    "                for part in parts:\n",
    "                    text = part.split(\"</div>\", 1)[0]\n",
    "                    # remove tags roughly\n",
    "                    txt = ''.join(c for c in text if c not in '<>/')\n",
    "                    snippets.append(txt.strip())\n",
    "        if not snippets:\n",
    "            # fallback: return the first 3000 characters of page as \"search result\"\n",
    "            return html[:3000]\n",
    "        return \"\\n\".join(snippets)[:3000]\n",
    "    except Exception as e:\n",
    "        return f\"ERROR_SEARCHING: {e}\"\n",
    "\n",
    "def fetch_website_html(url):\n",
    "    \"\"\"Robust website fetcher returning HTML or an error code string\"\"\"\n",
    "    if pd.isna(url) or str(url).strip() == \"\":\n",
    "        return \"NO_URL\"\n",
    "    try:\n",
    "        r = requests.get(url, headers=HEADERS, timeout=12)\n",
    "        if r.status_code != 200:\n",
    "            return f\"ERROR_HTTP_{r.status_code}\"\n",
    "        text = r.text\n",
    "        if not text or len(text.strip()) == 0:\n",
    "            return \"NO_HTML\"\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"ERROR_FETCHING_HTML: {e}\"\n",
    "\n",
    "# ========================================================\n",
    "# 4. OpenAI function-calling helper\n",
    "#    We'll expose one function \"perform_search\" to the model. If model calls it, we run it and re-invoke.\n",
    "# ========================================================\n",
    "FUNCTIONS = [\n",
    "    {\n",
    "        \"name\": \"perform_search\",\n",
    "        \"description\": \"Perform a web search and return short aggregated titles/snippets. Input is a simple query string.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"Search query\"},\n",
    "                \"num_results\": {\"type\": \"integer\", \"description\": \"Number of results to return\", \"default\": 5}\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "SYSTEM_INSTRUCTIONS = (\n",
    "    \"You are a classifier assistant. For each website you must respond with exactly one token: \"\n",
    "    \"'e-commerce', 'mark-ops', or 'other'.\\n\\n\"\n",
    "    \"You may call the tool 'perform_search' to fetch web search snippets that will help classification. \"\n",
    "    \"If you call the tool, you will receive the tool output and should then return only the final label string.\"\n",
    ")\n",
    "\n",
    "def classify_with_openai(url):\n",
    "    \"\"\"\n",
    "    Use OpenAI Chat Completion with function-calling flow (single tool).\n",
    "    Returns one of: 'e-commerce', 'mark-ops', 'other'\n",
    "    \"\"\"\n",
    "    if pd.isna(url) or str(url).strip() == \"\":\n",
    "        return \"other\"\n",
    "\n",
    "    # fetch partial website HTML for context (trimmed)\n",
    "    html = fetch_website_html(url)\n",
    "    html_trimmed = html[:5000] if isinstance(html, str) else str(html)[:5000]\n",
    "\n",
    "    user_prompt = (\n",
    "        f\"Analyze this website URL: {url}\\n\\n\"\n",
    "        \"I will provide the site's HTML (trimmed) below. Use the HTML and, if needed, call the perform_search tool to fetch web search snippets.\\n\\n\"\n",
    "        \"Website HTML (trimmed):\\n\"\n",
    "        \"---------------- HTML START ----------------\\n\"\n",
    "        f\"{html_trimmed}\\n\"\n",
    "        \"---------------- HTML END ----------------\\n\\n\"\n",
    "        \"Classify into one of: 'e-commerce', 'mark-ops', 'other'. Answer with only the one-word label and nothing else.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # initial call; allow the model to call the tool\n",
    "        resp = openai.ChatCompletion.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_INSTRUCTIONS},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            functions=FUNCTIONS,\n",
    "            function_call=\"auto\",\n",
    "            max_tokens=400,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        # If API request fails, fallback to \"other\"\n",
    "        print(f\"OpenAI API error: {e}\")\n",
    "        return \"other\"\n",
    "\n",
    "    # parse response\n",
    "    message = resp[\"choices\"][0][\"message\"]\n",
    "\n",
    "    # if model asked to call a function:\n",
    "    if message.get(\"function_call\"):\n",
    "        fname = message[\"function_call\"][\"name\"]\n",
    "        fargs_json = message[\"function_call\"].get(\"arguments\", \"{}\")\n",
    "        try:\n",
    "            fargs = json.loads(fargs_json)\n",
    "        except Exception:\n",
    "            fargs = {}\n",
    "        # Execute only perform_search for now\n",
    "        if fname == \"perform_search\":\n",
    "            q = fargs.get(\"query\") or url\n",
    "            num = int(fargs.get(\"num_results\", 5) or 5)\n",
    "            tool_out = perform_search(q, num_results=num)\n",
    "\n",
    "            # send the function result back to the model\n",
    "            try:\n",
    "                followup = openai.ChatCompletion.create(\n",
    "                    model=MODEL,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": SYSTEM_INSTRUCTIONS},\n",
    "                        {\"role\": \"user\", \"content\": user_prompt},\n",
    "                        {\n",
    "                            \"role\": \"assistant\",\n",
    "                            \"content\": None,\n",
    "                            \"function_call\": {\"name\": \"perform_search\", \"arguments\": json.dumps(fargs)}\n",
    "                        },\n",
    "                        {\"role\": \"function\", \"name\": \"perform_search\", \"content\": tool_out}\n",
    "                    ],\n",
    "                    max_tokens=200,\n",
    "                    temperature=0.0\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"OpenAI followup error: {e}\")\n",
    "                return \"other\"\n",
    "\n",
    "            final_msg = followup[\"choices\"][0][\"message\"]\n",
    "            final_text = (final_msg.get(\"content\") or \"\").strip().lower()\n",
    "            # ensure it's one of expected labels\n",
    "            if final_text in [\"e-commerce\", \"mark-ops\", \"other\"]:\n",
    "                return final_text\n",
    "            # sometimes model returns JSON or extra whitespace/newlines\n",
    "            # find if any expected label appears inside the output\n",
    "            for label in [\"e-commerce\", \"mark-ops\", \"other\"]:\n",
    "                if label in final_text:\n",
    "                    return label\n",
    "            # fallback\n",
    "            return \"other\"\n",
    "\n",
    "    else:\n",
    "        # model responded directly (no tool call)\n",
    "        text = (message.get(\"content\") or \"\").strip().lower()\n",
    "        if text in [\"e-commerce\", \"mark-ops\", \"other\"]:\n",
    "            return text\n",
    "        for label in [\"e-commerce\", \"mark-ops\", \"other\"]:\n",
    "            if label in text:\n",
    "                return label\n",
    "        return \"other\"\n",
    "\n",
    "# ========================================================\n",
    "# 5. Batch processing / main loop\n",
    "# ========================================================\n",
    "BATCH_SIZE = 15\n",
    "TOTAL = len(df)\n",
    "\n",
    "print(f\"Total rows: {TOTAL}\")\n",
    "print(f\"Processing from row {start_index}...\\n\")\n",
    "\n",
    "for batch_start in range(start_index, TOTAL, BATCH_SIZE):\n",
    "    batch_end = min(batch_start + BATCH_SIZE, TOTAL)\n",
    "\n",
    "    # clear screen on each batch (Windows 'cls', else 'clear')\n",
    "    os.system('cls' if os.name == 'nt' else 'clear')\n",
    "\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"PROCESSING BATCH {batch_start} → {batch_end - 1}\")\n",
    "    print(f\"==============================\\n\")\n",
    "\n",
    "    for i in range(batch_start, batch_end):\n",
    "        old_value = str(df.at[i, \"Category_Gemini\"]).strip().lower()\n",
    "\n",
    "        # final skip logic - skip if already labeled (non-empty)\n",
    "        if old_value not in [\"\", \"nan\", \"none\"]:\n",
    "            print(f\"⏩ Row {i} already classified ({old_value}) → Skipping\")\n",
    "            continue\n",
    "\n",
    "        url = df.at[i, \"Website\"]\n",
    "        print(f\"\\n🔵 Row {i} — URL: {url}\")\n",
    "\n",
    "        try:\n",
    "            category = run_with_timeout(classify_with_openai, args=(url,), timeout=30)\n",
    "\n",
    "            if category == \"TIMEOUT\":\n",
    "                print(\"⏱️ Timeout reached — skipping this URL\")\n",
    "                category = \"timeout\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error while classifying row {i}: {e}\")\n",
    "            category = \"other\"\n",
    "\n",
    "        df.at[i, \"Category_Gemini\"] = category\n",
    "        print(f\"✅ Classified as: {category}\\n\")\n",
    "\n",
    "    # Save progress to OUTPUT_PATH so future runs preserve these values\n",
    "    df.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(f\"💾 Progress saved to → {OUTPUT_PATH}\")\n",
    "\n",
    "    print(\"\\n⏳ Sleeping for 30 seconds...\\n\")\n",
    "    time.sleep(30)\n",
    "\n",
    "print(\"\\n🎉 ALL DONE — Entire CSV classified successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
